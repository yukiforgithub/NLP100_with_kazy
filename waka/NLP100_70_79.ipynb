{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第8章: ニューラルネット\n",
    "第6章で取り組んだニュース記事のカテゴリ分類を題材として，ニューラルネットワークでカテゴリ分類モデルを実装する．なお，この章ではPyTorch, TensorFlow, Chainerなどの機械学習プラットフォームを活用せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 70. 単語ベクトルの和による特徴量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "text = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "train_article=pd.read_csv('train.csv')\n",
    "val_article=pd.read_csv('val.csv')\n",
    "test_article=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_X_vec(article):\n",
    "    article_vec_accumulator=np.zeros((len(article),300))\n",
    "    counter=-1\n",
    "    for article_list in article.TITLE.tolist():\n",
    "        article_list=article_list.split(\" \")\n",
    "        counter+=1\n",
    "        predicted_value=[]\n",
    "        for word in article_list:\n",
    "            word=word.replace(\"'\",\"\")\n",
    "            try:\n",
    "                predicted_value.append(text[word])\n",
    "            except KeyError:\n",
    "                pass\n",
    "        article_vec_mean=np.array(predicted_value).mean(axis=0)\n",
    "        article_vec_accumulator[counter,:]=article_vec_mean\n",
    "    return article_vec_accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_label_dict={\n",
    "    \"b\":0,\n",
    "    \"t\":1,\n",
    "    \"e\":2,\n",
    "    \"m\":3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_y_sc(article):\n",
    "    article_sc_accumulator=np.zeros((len(article),1),dtype=int)\n",
    "    counter=-1\n",
    "    for category in article.CATEGORY.tolist():\n",
    "        label_id=category_label_dict[category]\n",
    "        counter+=1\n",
    "        article_sc_accumulator[counter,:]=label_id\n",
    "    return article_sc_accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train=create_X_vec(article=train_article)\n",
    "X_val=create_X_vec(article=val_article)\n",
    "X_test=create_X_vec(article=test_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train=create_y_sc(article=train_article)\n",
    "y_val=create_y_sc(article=val_article)\n",
    "y_test=create_y_sc(article=test_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 71. 単層ニューラルネットワークによる予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'],lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_train[:4,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 72. 損失と勾配の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot=np.zeros((len(y_train),4),dtype=int)\n",
    "for idx in range(len(y_train)):\n",
    "    y_train_one_hot[idx,:]=np.eye(4)[y_train[idx,:]]\n",
    "y_val_one_hot=np.zeros((len(y_val),4),dtype=int)\n",
    "for idx in range(len(y_val)):\n",
    "    y_val_one_hot[idx,:]=np.eye(4)[y_val[idx,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=y_train_one_hot[:4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "loss=losses.categorical_crossentropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4326589, 1.1892002, 1.4689921, 1.3275522], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "variables=X_train[:4,:]\n",
    "grad=K.gradients(loss, model.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 73. 確率的勾配降下法による学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3982 - accuracy: 0.8698\n",
      "Epoch 2/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3973 - accuracy: 0.8698\n",
      "Epoch 3/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3965 - accuracy: 0.8698\n",
      "Epoch 4/100\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.3956 - accuracy: 0.8707\n",
      "Epoch 5/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.3948 - accuracy: 0.8706\n",
      "Epoch 6/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3939 - accuracy: 0.8716\n",
      "Epoch 7/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.3931 - accuracy: 0.8714\n",
      "Epoch 8/100\n",
      "10685/10685 [==============================] - 0s 47us/step - loss: 0.3923 - accuracy: 0.8715\n",
      "Epoch 9/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3915 - accuracy: 0.8720\n",
      "Epoch 10/100\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.3908 - accuracy: 0.8717\n",
      "Epoch 11/100\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.3900 - accuracy: 0.8725\n",
      "Epoch 12/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3892 - accuracy: 0.8726\n",
      "Epoch 13/100\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.3885 - accuracy: 0.8730\n",
      "Epoch 14/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.3877 - accuracy: 0.8728\n",
      "Epoch 15/100\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.3870 - accuracy: 0.8730\n",
      "Epoch 16/100\n",
      "10685/10685 [==============================] - 1s 52us/step - loss: 0.3863 - accuracy: 0.8737\n",
      "Epoch 17/100\n",
      "10685/10685 [==============================] - 1s 64us/step - loss: 0.3856 - accuracy: 0.8735\n",
      "Epoch 18/100\n",
      "10685/10685 [==============================] - 1s 52us/step - loss: 0.3849 - accuracy: 0.8741\n",
      "Epoch 19/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3842 - accuracy: 0.8743\n",
      "Epoch 20/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.3835 - accuracy: 0.8746\n",
      "Epoch 21/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3828 - accuracy: 0.8745\n",
      "Epoch 22/100\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.3822 - accuracy: 0.8755\n",
      "Epoch 23/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3815 - accuracy: 0.8755\n",
      "Epoch 24/100\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.3809 - accuracy: 0.8757\n",
      "Epoch 25/100\n",
      "10685/10685 [==============================] - 1s 52us/step - loss: 0.3802 - accuracy: 0.8753\n",
      "Epoch 26/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.3796 - accuracy: 0.8762\n",
      "Epoch 27/100\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.3790 - accuracy: 0.8767\n",
      "Epoch 28/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.3784 - accuracy: 0.8765\n",
      "Epoch 29/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.3777 - accuracy: 0.8766\n",
      "Epoch 30/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.3771 - accuracy: 0.8772\n",
      "Epoch 31/100\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.3766 - accuracy: 0.8770\n",
      "Epoch 32/100\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.3760 - accuracy: 0.8773\n",
      "Epoch 33/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.3754 - accuracy: 0.8780\n",
      "Epoch 34/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.3748 - accuracy: 0.8781\n",
      "Epoch 35/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3743 - accuracy: 0.8781\n",
      "Epoch 36/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.3737 - accuracy: 0.8785\n",
      "Epoch 37/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3731 - accuracy: 0.8782\n",
      "Epoch 38/100\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.3726 - accuracy: 0.8784\n",
      "Epoch 39/100\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.3720 - accuracy: 0.8790\n",
      "Epoch 40/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.3715 - accuracy: 0.8793\n",
      "Epoch 41/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.3710 - accuracy: 0.8794\n",
      "Epoch 42/100\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.3705 - accuracy: 0.8801\n",
      "Epoch 43/100\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.3699 - accuracy: 0.8797\n",
      "Epoch 44/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.3694 - accuracy: 0.8804\n",
      "Epoch 45/100\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.3689 - accuracy: 0.8804\n",
      "Epoch 46/100\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.3684 - accuracy: 0.8808\n",
      "Epoch 47/100\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.3679 - accuracy: 0.8805\n",
      "Epoch 48/100\n",
      "10685/10685 [==============================] - 1s 52us/step - loss: 0.3674 - accuracy: 0.8810\n",
      "Epoch 49/100\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.3670 - accuracy: 0.8807\n",
      "Epoch 50/100\n",
      "10685/10685 [==============================] - 0s 47us/step - loss: 0.3665 - accuracy: 0.8815\n",
      "Epoch 51/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3660 - accuracy: 0.8812\n",
      "Epoch 52/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.3655 - accuracy: 0.8809\n",
      "Epoch 53/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.3651 - accuracy: 0.8814\n",
      "Epoch 54/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3646 - accuracy: 0.8819\n",
      "Epoch 55/100\n",
      "10685/10685 [==============================] - 0s 47us/step - loss: 0.3641 - accuracy: 0.8816\n",
      "Epoch 56/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3637 - accuracy: 0.8817\n",
      "Epoch 57/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.3632 - accuracy: 0.8817\n",
      "Epoch 58/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3628 - accuracy: 0.8821\n",
      "Epoch 59/100\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.3624 - accuracy: 0.8819\n",
      "Epoch 60/100\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.3619 - accuracy: 0.8823\n",
      "Epoch 61/100\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.3615 - accuracy: 0.8820\n",
      "Epoch 62/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3611 - accuracy: 0.8820\n",
      "Epoch 63/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.3606 - accuracy: 0.8822\n",
      "Epoch 64/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.3602 - accuracy: 0.8823\n",
      "Epoch 65/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.3598 - accuracy: 0.8825\n",
      "Epoch 66/100\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.3594 - accuracy: 0.8827\n",
      "Epoch 67/100\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.3590 - accuracy: 0.8830\n",
      "Epoch 68/100\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.3586 - accuracy: 0.8828\n",
      "Epoch 69/100\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.3582 - accuracy: 0.8830\n",
      "Epoch 70/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3578 - accuracy: 0.8830\n",
      "Epoch 71/100\n",
      "10685/10685 [==============================] - 0s 47us/step - loss: 0.3574 - accuracy: 0.8832\n",
      "Epoch 72/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.3570 - accuracy: 0.8835\n",
      "Epoch 73/100\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.3566 - accuracy: 0.8834\n",
      "Epoch 74/100\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.3563 - accuracy: 0.8831\n",
      "Epoch 75/100\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.3559 - accuracy: 0.8831\n",
      "Epoch 76/100\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.3555 - accuracy: 0.8832\n",
      "Epoch 77/100\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.3551 - accuracy: 0.8834\n",
      "Epoch 78/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3548 - accuracy: 0.8839\n",
      "Epoch 79/100\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.3544 - accuracy: 0.8836\n",
      "Epoch 80/100\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.3540 - accuracy: 0.8837\n",
      "Epoch 81/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3537 - accuracy: 0.8839\n",
      "Epoch 82/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.3533 - accuracy: 0.8839\n",
      "Epoch 83/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3530 - accuracy: 0.8839\n",
      "Epoch 84/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.3526 - accuracy: 0.8841\n",
      "Epoch 85/100\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.3523 - accuracy: 0.8842\n",
      "Epoch 86/100\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.3519 - accuracy: 0.8849\n",
      "Epoch 87/100\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.3516 - accuracy: 0.8845\n",
      "Epoch 88/100\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.3513 - accuracy: 0.8845\n",
      "Epoch 89/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.3509 - accuracy: 0.8846\n",
      "Epoch 90/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3506 - accuracy: 0.8850\n",
      "Epoch 91/100\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.3503 - accuracy: 0.8853\n",
      "Epoch 92/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3499 - accuracy: 0.8854\n",
      "Epoch 93/100\n",
      "10685/10685 [==============================] - 0s 47us/step - loss: 0.3496 - accuracy: 0.8853\n",
      "Epoch 94/100\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.3493 - accuracy: 0.8857\n",
      "Epoch 95/100\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.3490 - accuracy: 0.8861\n",
      "Epoch 96/100\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.3487 - accuracy: 0.8857\n",
      "Epoch 97/100\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.3483 - accuracy: 0.8859\n",
      "Epoch 98/100\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.3480 - accuracy: 0.8856\n",
      "Epoch 99/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3477 - accuracy: 0.8862\n",
      "Epoch 100/100\n",
      "10685/10685 [==============================] - 0s 47us/step - loss: 0.3474 - accuracy: 0.8861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2195ca6b888>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_one_hot, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 74. 正解率の計測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 0.8862891904539073\n",
      "test acc: 0.8921348314606742\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(f\"train acc: {accuracy_score(y_train,model.predict_classes(X_train))}\")\n",
    "print(f\"test acc: {accuracy_score(y_test,model.predict_classes(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10685, 300)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 75. 損失と正解率のプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10685 samples, validate on 1336 samples\n",
      "Epoch 1/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.3091 - accuracy: 0.8970 - val_loss: 0.3155 - val_accuracy: 0.8877\n",
      "Epoch 2/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3090 - accuracy: 0.8968 - val_loss: 0.3154 - val_accuracy: 0.8877\n",
      "Epoch 3/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.3089 - accuracy: 0.8971 - val_loss: 0.3153 - val_accuracy: 0.8877\n",
      "Epoch 4/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.3088 - accuracy: 0.8971 - val_loss: 0.3153 - val_accuracy: 0.8885\n",
      "Epoch 5/100\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.3088 - accuracy: 0.8973 - val_loss: 0.3152 - val_accuracy: 0.8885\n",
      "Epoch 6/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3086 - accuracy: 0.8971 - val_loss: 0.3151 - val_accuracy: 0.8877\n",
      "Epoch 7/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.3085 - accuracy: 0.8974 - val_loss: 0.3150 - val_accuracy: 0.8892\n",
      "Epoch 8/100\n",
      "10685/10685 [==============================] - 1s 56us/step - loss: 0.3084 - accuracy: 0.8974 - val_loss: 0.3150 - val_accuracy: 0.8892\n",
      "Epoch 9/100\n",
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.3084 - accuracy: 0.8977 - val_loss: 0.3149 - val_accuracy: 0.8892\n",
      "Epoch 10/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.3082 - accuracy: 0.8977 - val_loss: 0.3148 - val_accuracy: 0.8892\n",
      "Epoch 11/100\n",
      "10685/10685 [==============================] - 1s 54us/step - loss: 0.3082 - accuracy: 0.8975 - val_loss: 0.3148 - val_accuracy: 0.8892\n",
      "Epoch 12/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.3081 - accuracy: 0.8975 - val_loss: 0.3147 - val_accuracy: 0.8892\n",
      "Epoch 13/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.3080 - accuracy: 0.8978 - val_loss: 0.3146 - val_accuracy: 0.8892\n",
      "Epoch 14/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.3079 - accuracy: 0.8980 - val_loss: 0.3145 - val_accuracy: 0.8892\n",
      "Epoch 15/100\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.3078 - accuracy: 0.8979 - val_loss: 0.3144 - val_accuracy: 0.8892\n",
      "Epoch 16/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.3077 - accuracy: 0.8977 - val_loss: 0.3144 - val_accuracy: 0.8892\n",
      "Epoch 17/100\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.3076 - accuracy: 0.8979 - val_loss: 0.3143 - val_accuracy: 0.8892\n",
      "Epoch 18/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.3075 - accuracy: 0.8978 - val_loss: 0.3142 - val_accuracy: 0.8892\n",
      "Epoch 19/100\n",
      "10685/10685 [==============================] - 1s 56us/step - loss: 0.3074 - accuracy: 0.8977 - val_loss: 0.3141 - val_accuracy: 0.8892\n",
      "Epoch 20/100\n",
      "10685/10685 [==============================] - 1s 52us/step - loss: 0.3073 - accuracy: 0.8977 - val_loss: 0.3141 - val_accuracy: 0.8900\n",
      "Epoch 21/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3072 - accuracy: 0.8977 - val_loss: 0.3140 - val_accuracy: 0.8900\n",
      "Epoch 22/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.3071 - accuracy: 0.8977 - val_loss: 0.3139 - val_accuracy: 0.8900\n",
      "Epoch 23/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.3070 - accuracy: 0.8981 - val_loss: 0.3139 - val_accuracy: 0.8900\n",
      "Epoch 24/100\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.3069 - accuracy: 0.8976 - val_loss: 0.3138 - val_accuracy: 0.8900\n",
      "Epoch 25/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.3068 - accuracy: 0.8981 - val_loss: 0.3137 - val_accuracy: 0.8900\n",
      "Epoch 26/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3067 - accuracy: 0.8979 - val_loss: 0.3136 - val_accuracy: 0.8900\n",
      "Epoch 27/100\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.3066 - accuracy: 0.8978 - val_loss: 0.3136 - val_accuracy: 0.8900\n",
      "Epoch 28/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.3065 - accuracy: 0.8981 - val_loss: 0.3135 - val_accuracy: 0.8900\n",
      "Epoch 29/100\n",
      "10685/10685 [==============================] - 0s 47us/step - loss: 0.3064 - accuracy: 0.8982 - val_loss: 0.3134 - val_accuracy: 0.8900\n",
      "Epoch 30/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.3064 - accuracy: 0.8982 - val_loss: 0.3134 - val_accuracy: 0.8900\n",
      "Epoch 31/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.3063 - accuracy: 0.8983 - val_loss: 0.3133 - val_accuracy: 0.8900\n",
      "Epoch 32/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.3062 - accuracy: 0.8982 - val_loss: 0.3132 - val_accuracy: 0.8900\n",
      "Epoch 33/100\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.3061 - accuracy: 0.8983 - val_loss: 0.3131 - val_accuracy: 0.8900\n",
      "Epoch 34/100\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.3060 - accuracy: 0.8982 - val_loss: 0.3130 - val_accuracy: 0.8900\n",
      "Epoch 35/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.3059 - accuracy: 0.8982 - val_loss: 0.3130 - val_accuracy: 0.8900\n",
      "Epoch 36/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.3058 - accuracy: 0.8984 - val_loss: 0.3129 - val_accuracy: 0.8907\n",
      "Epoch 37/100\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.3057 - accuracy: 0.8985 - val_loss: 0.3128 - val_accuracy: 0.8900\n",
      "Epoch 38/100\n",
      "10685/10685 [==============================] - 1s 60us/step - loss: 0.3056 - accuracy: 0.8982 - val_loss: 0.3128 - val_accuracy: 0.8900\n",
      "Epoch 39/100\n",
      "10685/10685 [==============================] - 1s 56us/step - loss: 0.3055 - accuracy: 0.8982 - val_loss: 0.3127 - val_accuracy: 0.8900\n",
      "Epoch 40/100\n",
      "10685/10685 [==============================] - 1s 56us/step - loss: 0.3054 - accuracy: 0.8984 - val_loss: 0.3127 - val_accuracy: 0.8900\n",
      "Epoch 41/100\n",
      "10685/10685 [==============================] - 1s 56us/step - loss: 0.3054 - accuracy: 0.8985 - val_loss: 0.3126 - val_accuracy: 0.8907\n",
      "Epoch 42/100\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.3053 - accuracy: 0.8980 - val_loss: 0.3125 - val_accuracy: 0.8907\n",
      "Epoch 43/100\n",
      "10685/10685 [==============================] - 1s 56us/step - loss: 0.3052 - accuracy: 0.8983 - val_loss: 0.3125 - val_accuracy: 0.8907\n",
      "Epoch 44/100\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.3051 - accuracy: 0.8985 - val_loss: 0.3124 - val_accuracy: 0.8907\n",
      "Epoch 45/100\n",
      "10685/10685 [==============================] - 1s 52us/step - loss: 0.3050 - accuracy: 0.8985 - val_loss: 0.3124 - val_accuracy: 0.8907\n",
      "Epoch 46/100\n",
      "10685/10685 [==============================] - 1s 52us/step - loss: 0.3049 - accuracy: 0.8978 - val_loss: 0.3123 - val_accuracy: 0.8907\n",
      "Epoch 47/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.3048 - accuracy: 0.8985 - val_loss: 0.3122 - val_accuracy: 0.8907\n",
      "Epoch 48/100\n",
      "10685/10685 [==============================] - 1s 54us/step - loss: 0.3047 - accuracy: 0.8985 - val_loss: 0.3121 - val_accuracy: 0.8900\n",
      "Epoch 49/100\n",
      "10685/10685 [==============================] - 1s 54us/step - loss: 0.3047 - accuracy: 0.8984 - val_loss: 0.3120 - val_accuracy: 0.8900\n",
      "Epoch 50/100\n",
      "10685/10685 [==============================] - 1s 54us/step - loss: 0.3046 - accuracy: 0.8982 - val_loss: 0.3120 - val_accuracy: 0.8900\n",
      "Epoch 51/100\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.3045 - accuracy: 0.8984 - val_loss: 0.3119 - val_accuracy: 0.8900\n",
      "Epoch 52/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.3044 - accuracy: 0.8985 - val_loss: 0.3118 - val_accuracy: 0.8900\n",
      "Epoch 53/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.3043 - accuracy: 0.8987 - val_loss: 0.3118 - val_accuracy: 0.8900\n",
      "Epoch 54/100\n",
      "10685/10685 [==============================] - 1s 60us/step - loss: 0.3042 - accuracy: 0.8983 - val_loss: 0.3117 - val_accuracy: 0.8900\n",
      "Epoch 55/100\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.3041 - accuracy: 0.8986 - val_loss: 0.3116 - val_accuracy: 0.8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.3041 - accuracy: 0.8988 - val_loss: 0.3116 - val_accuracy: 0.8907\n",
      "Epoch 57/100\n",
      "10685/10685 [==============================] - 1s 69us/step - loss: 0.3040 - accuracy: 0.8987 - val_loss: 0.3115 - val_accuracy: 0.8900\n",
      "Epoch 58/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3039 - accuracy: 0.8987 - val_loss: 0.3114 - val_accuracy: 0.8907\n",
      "Epoch 59/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.3038 - accuracy: 0.8984 - val_loss: 0.3114 - val_accuracy: 0.8907\n",
      "Epoch 60/100\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.3037 - accuracy: 0.8988 - val_loss: 0.3113 - val_accuracy: 0.8907\n",
      "Epoch 61/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.3036 - accuracy: 0.8985 - val_loss: 0.3113 - val_accuracy: 0.8907\n",
      "Epoch 62/100\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.3035 - accuracy: 0.8985 - val_loss: 0.3112 - val_accuracy: 0.8907\n",
      "Epoch 63/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.3035 - accuracy: 0.8988 - val_loss: 0.3111 - val_accuracy: 0.8907\n",
      "Epoch 64/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.3034 - accuracy: 0.8990 - val_loss: 0.3111 - val_accuracy: 0.8907\n",
      "Epoch 65/100\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.3033 - accuracy: 0.8990 - val_loss: 0.3110 - val_accuracy: 0.8907\n",
      "Epoch 66/100\n",
      "10685/10685 [==============================] - 0s 47us/step - loss: 0.3032 - accuracy: 0.8989 - val_loss: 0.3110 - val_accuracy: 0.8907\n",
      "Epoch 67/100\n",
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.3031 - accuracy: 0.8991 - val_loss: 0.3109 - val_accuracy: 0.8907\n",
      "Epoch 68/100\n",
      "10685/10685 [==============================] - 1s 57us/step - loss: 0.3031 - accuracy: 0.8987 - val_loss: 0.3109 - val_accuracy: 0.8900\n",
      "Epoch 69/100\n",
      "10685/10685 [==============================] - 1s 63us/step - loss: 0.3030 - accuracy: 0.8992 - val_loss: 0.3108 - val_accuracy: 0.8907\n",
      "Epoch 70/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3029 - accuracy: 0.8992 - val_loss: 0.3107 - val_accuracy: 0.8907\n",
      "Epoch 71/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3028 - accuracy: 0.8991 - val_loss: 0.3106 - val_accuracy: 0.8907\n",
      "Epoch 72/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.3027 - accuracy: 0.8992 - val_loss: 0.3106 - val_accuracy: 0.8907\n",
      "Epoch 73/100\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.3026 - accuracy: 0.8990 - val_loss: 0.3105 - val_accuracy: 0.8907\n",
      "Epoch 74/100\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.3026 - accuracy: 0.8990 - val_loss: 0.3105 - val_accuracy: 0.8915\n",
      "Epoch 75/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3025 - accuracy: 0.8994 - val_loss: 0.3104 - val_accuracy: 0.8907\n",
      "Epoch 76/100\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.3024 - accuracy: 0.8987 - val_loss: 0.3103 - val_accuracy: 0.8915\n",
      "Epoch 77/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.3023 - accuracy: 0.8993 - val_loss: 0.3103 - val_accuracy: 0.8915\n",
      "Epoch 78/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3022 - accuracy: 0.8991 - val_loss: 0.3102 - val_accuracy: 0.8915\n",
      "Epoch 79/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.3022 - accuracy: 0.8992 - val_loss: 0.3102 - val_accuracy: 0.8915\n",
      "Epoch 80/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3021 - accuracy: 0.8995 - val_loss: 0.3101 - val_accuracy: 0.8915\n",
      "Epoch 81/100\n",
      "10685/10685 [==============================] - 0s 47us/step - loss: 0.3020 - accuracy: 0.8994 - val_loss: 0.3100 - val_accuracy: 0.8915\n",
      "Epoch 82/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.3019 - accuracy: 0.8998 - val_loss: 0.3100 - val_accuracy: 0.8915\n",
      "Epoch 83/100\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.3018 - accuracy: 0.8997 - val_loss: 0.3099 - val_accuracy: 0.8915\n",
      "Epoch 84/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3018 - accuracy: 0.8999 - val_loss: 0.3099 - val_accuracy: 0.8915\n",
      "Epoch 85/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.3017 - accuracy: 0.8995 - val_loss: 0.3099 - val_accuracy: 0.8915\n",
      "Epoch 86/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.3016 - accuracy: 0.8995 - val_loss: 0.3098 - val_accuracy: 0.8915\n",
      "Epoch 87/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3015 - accuracy: 0.8996 - val_loss: 0.3097 - val_accuracy: 0.8915\n",
      "Epoch 88/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3015 - accuracy: 0.8996 - val_loss: 0.3096 - val_accuracy: 0.8915\n",
      "Epoch 89/100\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.3014 - accuracy: 0.8998 - val_loss: 0.3095 - val_accuracy: 0.8915\n",
      "Epoch 90/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3013 - accuracy: 0.8995 - val_loss: 0.3095 - val_accuracy: 0.8915\n",
      "Epoch 91/100\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.3012 - accuracy: 0.8996 - val_loss: 0.3095 - val_accuracy: 0.8915\n",
      "Epoch 92/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.3011 - accuracy: 0.8993 - val_loss: 0.3094 - val_accuracy: 0.8915\n",
      "Epoch 93/100\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.3011 - accuracy: 0.8999 - val_loss: 0.3094 - val_accuracy: 0.8922\n",
      "Epoch 94/100\n",
      "10685/10685 [==============================] - 0s 47us/step - loss: 0.3010 - accuracy: 0.8994 - val_loss: 0.3093 - val_accuracy: 0.8922\n",
      "Epoch 95/100\n",
      "10685/10685 [==============================] - 0s 47us/step - loss: 0.3009 - accuracy: 0.8995 - val_loss: 0.3092 - val_accuracy: 0.8922\n",
      "Epoch 96/100\n",
      "10685/10685 [==============================] - 1s 54us/step - loss: 0.3008 - accuracy: 0.8995 - val_loss: 0.3092 - val_accuracy: 0.8922\n",
      "Epoch 97/100\n",
      "10685/10685 [==============================] - 1s 54us/step - loss: 0.3008 - accuracy: 0.8998 - val_loss: 0.3091 - val_accuracy: 0.8915\n",
      "Epoch 98/100\n",
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.3007 - accuracy: 0.8999 - val_loss: 0.3091 - val_accuracy: 0.8922\n",
      "Epoch 99/100\n",
      "10685/10685 [==============================] - 1s 63us/step - loss: 0.3006 - accuracy: 0.8999 - val_loss: 0.3090 - val_accuracy: 0.8922\n",
      "Epoch 100/100\n",
      "10685/10685 [==============================] - 1s 54us/step - loss: 0.3005 - accuracy: 0.8991 - val_loss: 0.3090 - val_accuracy: 0.8922\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train_one_hot,\n",
    "                  validation_data=(X_val, y_val_one_hot), \n",
    "                  epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'acc')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.ylabel(\"loss\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.ylabel(\"acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 76. チェックポイント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10685 samples, validate on 1336 samples\n",
      "Epoch 1/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.3005 - accuracy: 0.8997 - val_loss: 0.3089 - val_accuracy: 0.8922\n",
      "Epoch 2/100\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.3004 - accuracy: 0.9000 - val_loss: 0.3089 - val_accuracy: 0.8922\n",
      "Epoch 3/100\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.3003 - accuracy: 0.8996 - val_loss: 0.3088 - val_accuracy: 0.8922\n",
      "Epoch 4/100\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.3002 - accuracy: 0.8996 - val_loss: 0.3088 - val_accuracy: 0.8922\n",
      "Epoch 5/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.3002 - accuracy: 0.8998 - val_loss: 0.3087 - val_accuracy: 0.8922\n",
      "Epoch 6/100\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.3001 - accuracy: 0.8998 - val_loss: 0.3086 - val_accuracy: 0.8922\n",
      "Epoch 7/100\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.3000 - accuracy: 0.8999 - val_loss: 0.3086 - val_accuracy: 0.8922\n",
      "Epoch 8/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2999 - accuracy: 0.8999 - val_loss: 0.3086 - val_accuracy: 0.8922\n",
      "Epoch 9/100\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.2999 - accuracy: 0.8998 - val_loss: 0.3085 - val_accuracy: 0.8922\n",
      "Epoch 10/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2998 - accuracy: 0.8996 - val_loss: 0.3085 - val_accuracy: 0.8922\n",
      "Epoch 11/100\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.2997 - accuracy: 0.8999 - val_loss: 0.3084 - val_accuracy: 0.8922\n",
      "Epoch 12/100\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.2997 - accuracy: 0.8998 - val_loss: 0.3083 - val_accuracy: 0.8930\n",
      "Epoch 13/100\n",
      "10685/10685 [==============================] - 1s 54us/step - loss: 0.2996 - accuracy: 0.9000 - val_loss: 0.3083 - val_accuracy: 0.8930\n",
      "Epoch 14/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2995 - accuracy: 0.9000 - val_loss: 0.3082 - val_accuracy: 0.8930\n",
      "Epoch 15/100\n",
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.2994 - accuracy: 0.8998 - val_loss: 0.3082 - val_accuracy: 0.8930\n",
      "Epoch 16/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2994 - accuracy: 0.9000 - val_loss: 0.3081 - val_accuracy: 0.8937\n",
      "Epoch 17/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2993 - accuracy: 0.9000 - val_loss: 0.3081 - val_accuracy: 0.8945\n",
      "Epoch 18/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2992 - accuracy: 0.9001 - val_loss: 0.3080 - val_accuracy: 0.8945\n",
      "Epoch 19/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.2991 - accuracy: 0.9004 - val_loss: 0.3080 - val_accuracy: 0.8945\n",
      "Epoch 20/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.2991 - accuracy: 0.8999 - val_loss: 0.3079 - val_accuracy: 0.8945\n",
      "Epoch 21/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2990 - accuracy: 0.9000 - val_loss: 0.3079 - val_accuracy: 0.8945\n",
      "Epoch 22/100\n",
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.2989 - accuracy: 0.9003 - val_loss: 0.3078 - val_accuracy: 0.8945\n",
      "Epoch 23/100\n",
      "10685/10685 [==============================] - 1s 65us/step - loss: 0.2989 - accuracy: 0.9000 - val_loss: 0.3078 - val_accuracy: 0.8945\n",
      "Epoch 24/100\n",
      "10685/10685 [==============================] - 1s 60us/step - loss: 0.2988 - accuracy: 0.9000 - val_loss: 0.3077 - val_accuracy: 0.8945\n",
      "Epoch 25/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2987 - accuracy: 0.9002 - val_loss: 0.3077 - val_accuracy: 0.8945\n",
      "Epoch 26/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2986 - accuracy: 0.9004 - val_loss: 0.3076 - val_accuracy: 0.8945\n",
      "Epoch 27/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2986 - accuracy: 0.9000 - val_loss: 0.3076 - val_accuracy: 0.8945\n",
      "Epoch 28/100\n",
      "10685/10685 [==============================] - 0s 47us/step - loss: 0.2985 - accuracy: 0.9000 - val_loss: 0.3075 - val_accuracy: 0.8945\n",
      "Epoch 29/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2984 - accuracy: 0.8997 - val_loss: 0.3075 - val_accuracy: 0.8945\n",
      "Epoch 30/100\n",
      "10685/10685 [==============================] - 0s 47us/step - loss: 0.2984 - accuracy: 0.9002 - val_loss: 0.3074 - val_accuracy: 0.8945\n",
      "Epoch 31/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2983 - accuracy: 0.9001 - val_loss: 0.3074 - val_accuracy: 0.8945\n",
      "Epoch 32/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2982 - accuracy: 0.8998 - val_loss: 0.3073 - val_accuracy: 0.8945\n",
      "Epoch 33/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2982 - accuracy: 0.9003 - val_loss: 0.3073 - val_accuracy: 0.8945\n",
      "Epoch 34/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2981 - accuracy: 0.9001 - val_loss: 0.3072 - val_accuracy: 0.8945\n",
      "Epoch 35/100\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.2980 - accuracy: 0.9000 - val_loss: 0.3072 - val_accuracy: 0.8945\n",
      "Epoch 36/100\n",
      "10685/10685 [==============================] - 1s 62us/step - loss: 0.2980 - accuracy: 0.9000 - val_loss: 0.3071 - val_accuracy: 0.8945\n",
      "Epoch 37/100\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.2979 - accuracy: 0.9003 - val_loss: 0.3071 - val_accuracy: 0.8945\n",
      "Epoch 38/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.2978 - accuracy: 0.9005 - val_loss: 0.3070 - val_accuracy: 0.8945\n",
      "Epoch 39/100\n",
      "10685/10685 [==============================] - 1s 60us/step - loss: 0.2977 - accuracy: 0.9003 - val_loss: 0.3070 - val_accuracy: 0.8945\n",
      "Epoch 40/100\n",
      "10685/10685 [==============================] - 1s 52us/step - loss: 0.2977 - accuracy: 0.9000 - val_loss: 0.3069 - val_accuracy: 0.8945\n",
      "Epoch 41/100\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.2976 - accuracy: 0.9001 - val_loss: 0.3069 - val_accuracy: 0.8945\n",
      "Epoch 42/100\n",
      "10685/10685 [==============================] - 1s 52us/step - loss: 0.2975 - accuracy: 0.9005 - val_loss: 0.3069 - val_accuracy: 0.8945\n",
      "Epoch 43/100\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.2975 - accuracy: 0.9005 - val_loss: 0.3068 - val_accuracy: 0.8945\n",
      "Epoch 44/100\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.2974 - accuracy: 0.9004 - val_loss: 0.3068 - val_accuracy: 0.8945\n",
      "Epoch 45/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2973 - accuracy: 0.9002 - val_loss: 0.3067 - val_accuracy: 0.8945\n",
      "Epoch 46/100\n",
      "10685/10685 [==============================] - 1s 54us/step - loss: 0.2973 - accuracy: 0.9000 - val_loss: 0.3067 - val_accuracy: 0.8945\n",
      "Epoch 47/100\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.2972 - accuracy: 0.9000 - val_loss: 0.3066 - val_accuracy: 0.8945\n",
      "Epoch 48/100\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.2971 - accuracy: 0.9004 - val_loss: 0.3066 - val_accuracy: 0.8945\n",
      "Epoch 49/100\n",
      "10685/10685 [==============================] - 0s 47us/step - loss: 0.2971 - accuracy: 0.9004 - val_loss: 0.3065 - val_accuracy: 0.8945\n",
      "Epoch 50/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2970 - accuracy: 0.9002 - val_loss: 0.3065 - val_accuracy: 0.8945\n",
      "Epoch 51/100\n",
      "10685/10685 [==============================] - 1s 66us/step - loss: 0.2969 - accuracy: 0.9002 - val_loss: 0.3064 - val_accuracy: 0.8945\n",
      "Epoch 52/100\n",
      "10685/10685 [==============================] - 1s 58us/step - loss: 0.2969 - accuracy: 0.9007 - val_loss: 0.3064 - val_accuracy: 0.8945\n",
      "Epoch 53/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2968 - accuracy: 0.9001 - val_loss: 0.3063 - val_accuracy: 0.8945\n",
      "Epoch 54/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2967 - accuracy: 0.9007 - val_loss: 0.3063 - val_accuracy: 0.8945\n",
      "Epoch 55/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2967 - accuracy: 0.9004 - val_loss: 0.3063 - val_accuracy: 0.8945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2966 - accuracy: 0.9004 - val_loss: 0.3062 - val_accuracy: 0.8945\n",
      "Epoch 57/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2966 - accuracy: 0.9005 - val_loss: 0.3061 - val_accuracy: 0.8945\n",
      "Epoch 58/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2965 - accuracy: 0.9007 - val_loss: 0.3061 - val_accuracy: 0.8945\n",
      "Epoch 59/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2964 - accuracy: 0.9008 - val_loss: 0.3061 - val_accuracy: 0.8945\n",
      "Epoch 60/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2964 - accuracy: 0.9003 - val_loss: 0.3060 - val_accuracy: 0.8952\n",
      "Epoch 61/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.2963 - accuracy: 0.9007 - val_loss: 0.3060 - val_accuracy: 0.8952\n",
      "Epoch 62/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2962 - accuracy: 0.9007 - val_loss: 0.3059 - val_accuracy: 0.8952\n",
      "Epoch 63/100\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.2962 - accuracy: 0.9004 - val_loss: 0.3059 - val_accuracy: 0.8952\n",
      "Epoch 64/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2961 - accuracy: 0.9010 - val_loss: 0.3058 - val_accuracy: 0.8952\n",
      "Epoch 65/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.2960 - accuracy: 0.9009 - val_loss: 0.3058 - val_accuracy: 0.8952\n",
      "Epoch 66/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.2960 - accuracy: 0.9012 - val_loss: 0.3057 - val_accuracy: 0.8952\n",
      "Epoch 67/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2959 - accuracy: 0.9010 - val_loss: 0.3057 - val_accuracy: 0.8952\n",
      "Epoch 68/100\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2958 - accuracy: 0.9010 - val_loss: 0.3057 - val_accuracy: 0.8952\n",
      "Epoch 69/100\n",
      "10685/10685 [==============================] - 0s 47us/step - loss: 0.2958 - accuracy: 0.9009 - val_loss: 0.3056 - val_accuracy: 0.8952\n",
      "Epoch 70/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.2957 - accuracy: 0.9010 - val_loss: 0.3056 - val_accuracy: 0.8952\n",
      "Epoch 71/100\n",
      "10685/10685 [==============================] - 1s 59us/step - loss: 0.2957 - accuracy: 0.9009 - val_loss: 0.3055 - val_accuracy: 0.8952\n",
      "Epoch 72/100\n",
      "10685/10685 [==============================] - 1s 59us/step - loss: 0.2956 - accuracy: 0.9007 - val_loss: 0.3055 - val_accuracy: 0.8945\n",
      "Epoch 73/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2955 - accuracy: 0.9011 - val_loss: 0.3055 - val_accuracy: 0.8945\n",
      "Epoch 74/100\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.2955 - accuracy: 0.9008 - val_loss: 0.3054 - val_accuracy: 0.8952\n",
      "Epoch 75/100\n",
      "10685/10685 [==============================] - 1s 67us/step - loss: 0.2954 - accuracy: 0.9013 - val_loss: 0.3054 - val_accuracy: 0.8945\n",
      "Epoch 76/100\n",
      "10685/10685 [==============================] - 1s 56us/step - loss: 0.2953 - accuracy: 0.9009 - val_loss: 0.3054 - val_accuracy: 0.8945\n",
      "Epoch 77/100\n",
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.2953 - accuracy: 0.9010 - val_loss: 0.3053 - val_accuracy: 0.8945\n",
      "Epoch 78/100\n",
      "10685/10685 [==============================] - 1s 58us/step - loss: 0.2952 - accuracy: 0.9012 - val_loss: 0.3052 - val_accuracy: 0.8945\n",
      "Epoch 79/100\n",
      "10685/10685 [==============================] - 1s 52us/step - loss: 0.2952 - accuracy: 0.9010 - val_loss: 0.3052 - val_accuracy: 0.8945\n",
      "Epoch 80/100\n",
      "10685/10685 [==============================] - 1s 65us/step - loss: 0.2951 - accuracy: 0.9010 - val_loss: 0.3051 - val_accuracy: 0.8952\n",
      "Epoch 81/100\n",
      "10685/10685 [==============================] - 1s 67us/step - loss: 0.2950 - accuracy: 0.9009 - val_loss: 0.3051 - val_accuracy: 0.8952\n",
      "Epoch 82/100\n",
      "10685/10685 [==============================] - 1s 67us/step - loss: 0.2950 - accuracy: 0.9008 - val_loss: 0.3050 - val_accuracy: 0.8952\n",
      "Epoch 83/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2949 - accuracy: 0.9008 - val_loss: 0.3050 - val_accuracy: 0.8952\n",
      "Epoch 84/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2948 - accuracy: 0.9014 - val_loss: 0.3050 - val_accuracy: 0.8952\n",
      "Epoch 85/100\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2948 - accuracy: 0.9010 - val_loss: 0.3049 - val_accuracy: 0.8945\n",
      "Epoch 86/100\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2947 - accuracy: 0.9013 - val_loss: 0.3049 - val_accuracy: 0.8945\n",
      "Epoch 87/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2947 - accuracy: 0.9012 - val_loss: 0.3048 - val_accuracy: 0.8945\n",
      "Epoch 88/100\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.2946 - accuracy: 0.9009 - val_loss: 0.3048 - val_accuracy: 0.8945\n",
      "Epoch 89/100\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.2945 - accuracy: 0.9012 - val_loss: 0.3048 - val_accuracy: 0.8945\n",
      "Epoch 90/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2945 - accuracy: 0.9010 - val_loss: 0.3047 - val_accuracy: 0.8945\n",
      "Epoch 91/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2944 - accuracy: 0.9011 - val_loss: 0.3047 - val_accuracy: 0.8945\n",
      "Epoch 92/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2944 - accuracy: 0.9008 - val_loss: 0.3046 - val_accuracy: 0.8945\n",
      "Epoch 93/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2943 - accuracy: 0.9012 - val_loss: 0.3046 - val_accuracy: 0.8945\n",
      "Epoch 94/100\n",
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.2942 - accuracy: 0.9013 - val_loss: 0.3046 - val_accuracy: 0.8945\n",
      "Epoch 95/100\n",
      "10685/10685 [==============================] - 1s 56us/step - loss: 0.2942 - accuracy: 0.9011 - val_loss: 0.3045 - val_accuracy: 0.8945\n",
      "Epoch 96/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2941 - accuracy: 0.9010 - val_loss: 0.3045 - val_accuracy: 0.8945\n",
      "Epoch 97/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2941 - accuracy: 0.9013 - val_loss: 0.3044 - val_accuracy: 0.8945\n",
      "Epoch 98/100\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.2940 - accuracy: 0.9015 - val_loss: 0.3044 - val_accuracy: 0.8945\n",
      "Epoch 99/100\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.2939 - accuracy: 0.9010 - val_loss: 0.3044 - val_accuracy: 0.8945\n",
      "Epoch 100/100\n",
      "10685/10685 [==============================] - 0s 47us/step - loss: 0.2939 - accuracy: 0.9012 - val_loss: 0.3044 - val_accuracy: 0.8945\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint =ModelCheckpoint(filepath=\"model-{epoch:02d}-{val_loss:.2f}.h5\", monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=50)\n",
    "history=model.fit(X_train, y_train_one_hot,\n",
    "                  validation_data=(X_val, y_val_one_hot), \n",
    "                  epochs=100,\n",
    "                 callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 77. ミニバッチ化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10685 samples, validate on 1336 samples\n",
      "Epoch 1/1\n",
      "10685/10685 [==============================] - 15s 1ms/step - loss: 0.2867 - accuracy: 0.9018 - val_loss: 0.3000 - val_accuracy: 0.8930\n",
      "Train on 10685 samples, validate on 1336 samples\n",
      "Epoch 1/1\n",
      "10685/10685 [==============================] - 9s 845us/step - loss: 0.2850 - accuracy: 0.9029 - val_loss: 0.2982 - val_accuracy: 0.8937\n",
      "Train on 10685 samples, validate on 1336 samples\n",
      "Epoch 1/1\n",
      "10685/10685 [==============================] - 4s 392us/step - loss: 0.2841 - accuracy: 0.9035 - val_loss: 0.2986 - val_accuracy: 0.8930\n",
      "Train on 10685 samples, validate on 1336 samples\n",
      "Epoch 1/1\n",
      "10685/10685 [==============================] - 2s 192us/step - loss: 0.2837 - accuracy: 0.9039 - val_loss: 0.2979 - val_accuracy: 0.8922\n",
      "Train on 10685 samples, validate on 1336 samples\n",
      "Epoch 1/1\n",
      "10685/10685 [==============================] - 1s 107us/step - loss: 0.2834 - accuracy: 0.9039 - val_loss: 0.2979 - val_accuracy: 0.8930\n",
      "Train on 10685 samples, validate on 1336 samples\n",
      "Epoch 1/1\n",
      "10685/10685 [==============================] - 1s 65us/step - loss: 0.2833 - accuracy: 0.9043 - val_loss: 0.2978 - val_accuracy: 0.8930\n",
      "Train on 10685 samples, validate on 1336 samples\n",
      "Epoch 1/1\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2832 - accuracy: 0.9044 - val_loss: 0.2978 - val_accuracy: 0.8930\n",
      "Train on 10685 samples, validate on 1336 samples\n",
      "Epoch 1/1\n",
      "10685/10685 [==============================] - 0s 25us/step - loss: 0.2832 - accuracy: 0.9044 - val_loss: 0.2978 - val_accuracy: 0.8930\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time_dict={}\n",
    "for batch_size in [1,2,4,8,16,32,64,128]:\n",
    "    start_time=time.time()\n",
    "    history=model.fit(X_train, y_train_one_hot,\n",
    "                      validation_data=(X_val, y_val_one_hot), \n",
    "                      epochs=1,\n",
    "                     batch_size=batch_size)\n",
    "    time_dict[batch_size]=time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 1: 14.616271734237671\n",
      "batch_size 2: 9.031636714935303\n",
      "batch_size 4: 4.194730997085571\n",
      "batch_size 8: 2.0563690662384033\n",
      "batch_size 16: 1.1417005062103271\n",
      "batch_size 32: 0.6982882022857666\n",
      "batch_size 64: 0.469728946685791\n",
      "batch_size 128: 0.27184605598449707\n"
     ]
    }
   ],
   "source": [
    "for key in time_dict:\n",
    "    print(f'batch_size {key}: {time_dict[key]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 78. GPU上での学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10685 samples, validate on 1336 samples\n",
      "Epoch 1/100\n",
      "10685/10685 [==============================] - 1s 58us/step - loss: 0.2832 - accuracy: 0.9044 - val_loss: 0.2978 - val_accuracy: 0.8930\n",
      "Epoch 2/100\n",
      "10685/10685 [==============================] - 1s 56us/step - loss: 0.2832 - accuracy: 0.9040 - val_loss: 0.2978 - val_accuracy: 0.8922\n",
      "Epoch 3/100\n",
      "10685/10685 [==============================] - 1s 64us/step - loss: 0.2831 - accuracy: 0.9045 - val_loss: 0.2978 - val_accuracy: 0.8922\n",
      "Epoch 4/100\n",
      "10685/10685 [==============================] - 1s 63us/step - loss: 0.2831 - accuracy: 0.9044 - val_loss: 0.2978 - val_accuracy: 0.8922\n",
      "Epoch 5/100\n",
      "10685/10685 [==============================] - 1s 60us/step - loss: 0.2831 - accuracy: 0.9045 - val_loss: 0.2978 - val_accuracy: 0.8922\n",
      "Epoch 6/100\n",
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.2830 - accuracy: 0.9044 - val_loss: 0.2977 - val_accuracy: 0.8922\n",
      "Epoch 7/100\n",
      "10685/10685 [==============================] - 1s 61us/step - loss: 0.2830 - accuracy: 0.9047 - val_loss: 0.2977 - val_accuracy: 0.8922\n",
      "Epoch 8/100\n",
      "10685/10685 [==============================] - 1s 59us/step - loss: 0.2829 - accuracy: 0.9045 - val_loss: 0.2977 - val_accuracy: 0.8922\n",
      "Epoch 9/100\n",
      "10685/10685 [==============================] - 1s 67us/step - loss: 0.2829 - accuracy: 0.9044 - val_loss: 0.2976 - val_accuracy: 0.8922\n",
      "Epoch 10/100\n",
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.2829 - accuracy: 0.9047 - val_loss: 0.2976 - val_accuracy: 0.8922\n",
      "Epoch 11/100\n",
      "10685/10685 [==============================] - 1s 61us/step - loss: 0.2828 - accuracy: 0.9046 - val_loss: 0.2976 - val_accuracy: 0.8922\n",
      "Epoch 12/100\n",
      "10685/10685 [==============================] - 1s 61us/step - loss: 0.2828 - accuracy: 0.9045 - val_loss: 0.2976 - val_accuracy: 0.8922\n",
      "Epoch 13/100\n",
      "10685/10685 [==============================] - 1s 62us/step - loss: 0.2827 - accuracy: 0.9041 - val_loss: 0.2975 - val_accuracy: 0.8930\n",
      "Epoch 14/100\n",
      "10685/10685 [==============================] - 1s 63us/step - loss: 0.2827 - accuracy: 0.9044 - val_loss: 0.2975 - val_accuracy: 0.8930\n",
      "Epoch 15/100\n",
      "10685/10685 [==============================] - 1s 60us/step - loss: 0.2827 - accuracy: 0.9047 - val_loss: 0.2975 - val_accuracy: 0.8930\n",
      "Epoch 16/100\n",
      "10685/10685 [==============================] - 1s 56us/step - loss: 0.2826 - accuracy: 0.9047 - val_loss: 0.2975 - val_accuracy: 0.8930\n",
      "Epoch 17/100\n",
      "10685/10685 [==============================] - 1s 56us/step - loss: 0.2826 - accuracy: 0.9049 - val_loss: 0.2975 - val_accuracy: 0.8930\n",
      "Epoch 18/100\n",
      "10685/10685 [==============================] - 1s 60us/step - loss: 0.2826 - accuracy: 0.9044 - val_loss: 0.2975 - val_accuracy: 0.8930\n",
      "Epoch 19/100\n",
      "10685/10685 [==============================] - 1s 74us/step - loss: 0.2825 - accuracy: 0.9049 - val_loss: 0.2974 - val_accuracy: 0.8930\n",
      "Epoch 20/100\n",
      "10685/10685 [==============================] - 1s 83us/step - loss: 0.2825 - accuracy: 0.9045 - val_loss: 0.2974 - val_accuracy: 0.8922\n",
      "Epoch 21/100\n",
      "10685/10685 [==============================] - 1s 59us/step - loss: 0.2824 - accuracy: 0.9046 - val_loss: 0.2974 - val_accuracy: 0.8930\n",
      "Epoch 22/100\n",
      "10685/10685 [==============================] - 1s 56us/step - loss: 0.2824 - accuracy: 0.9047 - val_loss: 0.2974 - val_accuracy: 0.8930\n",
      "Epoch 23/100\n",
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.2824 - accuracy: 0.9046 - val_loss: 0.2973 - val_accuracy: 0.8930\n",
      "Epoch 24/100\n",
      "10685/10685 [==============================] - 1s 59us/step - loss: 0.2823 - accuracy: 0.9047 - val_loss: 0.2973 - val_accuracy: 0.8930\n",
      "Epoch 25/100\n",
      "10685/10685 [==============================] - 1s 59us/step - loss: 0.2823 - accuracy: 0.9044 - val_loss: 0.2973 - val_accuracy: 0.8930\n",
      "Epoch 26/100\n",
      "10685/10685 [==============================] - 1s 87us/step - loss: 0.2823 - accuracy: 0.9049 - val_loss: 0.2973 - val_accuracy: 0.8930\n",
      "Epoch 27/100\n",
      "10685/10685 [==============================] - 1s 87us/step - loss: 0.2822 - accuracy: 0.9045 - val_loss: 0.2973 - val_accuracy: 0.8930\n",
      "Epoch 28/100\n",
      "10685/10685 [==============================] - 1s 107us/step - loss: 0.2822 - accuracy: 0.9045 - val_loss: 0.2973 - val_accuracy: 0.8930\n",
      "Epoch 29/100\n",
      "10685/10685 [==============================] - 1s 102us/step - loss: 0.2822 - accuracy: 0.9050 - val_loss: 0.2972 - val_accuracy: 0.8930\n",
      "Epoch 30/100\n",
      "10685/10685 [==============================] - 1s 78us/step - loss: 0.2821 - accuracy: 0.9048 - val_loss: 0.2972 - val_accuracy: 0.8930\n",
      "Epoch 31/100\n",
      "10685/10685 [==============================] - 1s 74us/step - loss: 0.2821 - accuracy: 0.9046 - val_loss: 0.2972 - val_accuracy: 0.8930\n",
      "Epoch 32/100\n",
      "10685/10685 [==============================] - 1s 71us/step - loss: 0.2820 - accuracy: 0.9046 - val_loss: 0.2971 - val_accuracy: 0.8930\n",
      "Epoch 33/100\n",
      "10685/10685 [==============================] - 1s 66us/step - loss: 0.2820 - accuracy: 0.9046 - val_loss: 0.2971 - val_accuracy: 0.8930\n",
      "Epoch 34/100\n",
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.2820 - accuracy: 0.9047 - val_loss: 0.2971 - val_accuracy: 0.8930\n",
      "Epoch 35/100\n",
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.2819 - accuracy: 0.9047 - val_loss: 0.2971 - val_accuracy: 0.8930\n",
      "Epoch 36/100\n",
      "10685/10685 [==============================] - 1s 59us/step - loss: 0.2819 - accuracy: 0.9049 - val_loss: 0.2971 - val_accuracy: 0.8937\n",
      "Epoch 37/100\n",
      "10685/10685 [==============================] - 1s 59us/step - loss: 0.2819 - accuracy: 0.9049 - val_loss: 0.2970 - val_accuracy: 0.8937\n",
      "Epoch 38/100\n",
      "10685/10685 [==============================] - 1s 66us/step - loss: 0.2818 - accuracy: 0.9049 - val_loss: 0.2970 - val_accuracy: 0.8930\n",
      "Epoch 39/100\n",
      "10685/10685 [==============================] - 1s 93us/step - loss: 0.2818 - accuracy: 0.9045 - val_loss: 0.2970 - val_accuracy: 0.8937\n",
      "Epoch 40/100\n",
      "10685/10685 [==============================] - 1s 76us/step - loss: 0.2817 - accuracy: 0.9050 - val_loss: 0.2970 - val_accuracy: 0.8937\n",
      "Epoch 41/100\n",
      "10685/10685 [==============================] - 1s 59us/step - loss: 0.2817 - accuracy: 0.9047 - val_loss: 0.2970 - val_accuracy: 0.8930\n",
      "Epoch 42/100\n",
      "10685/10685 [==============================] - 1s 58us/step - loss: 0.2817 - accuracy: 0.9047 - val_loss: 0.2969 - val_accuracy: 0.8930\n",
      "Epoch 43/100\n",
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.2816 - accuracy: 0.9050 - val_loss: 0.2969 - val_accuracy: 0.8930\n",
      "Epoch 44/100\n",
      "10685/10685 [==============================] - 1s 58us/step - loss: 0.2816 - accuracy: 0.9048 - val_loss: 0.2969 - val_accuracy: 0.8937\n",
      "Epoch 45/100\n",
      "10685/10685 [==============================] - 1s 78us/step - loss: 0.2816 - accuracy: 0.9048 - val_loss: 0.2969 - val_accuracy: 0.8937\n",
      "Epoch 46/100\n",
      "10685/10685 [==============================] - 1s 84us/step - loss: 0.2815 - accuracy: 0.9048 - val_loss: 0.2969 - val_accuracy: 0.8937\n",
      "Epoch 47/100\n",
      "10685/10685 [==============================] - 1s 80us/step - loss: 0.2815 - accuracy: 0.9051 - val_loss: 0.2969 - val_accuracy: 0.8930\n",
      "Epoch 48/100\n",
      "10685/10685 [==============================] - 1s 81us/step - loss: 0.2815 - accuracy: 0.9048 - val_loss: 0.2969 - val_accuracy: 0.8930\n",
      "Epoch 49/100\n",
      "10685/10685 [==============================] - 1s 95us/step - loss: 0.2814 - accuracy: 0.9049 - val_loss: 0.2968 - val_accuracy: 0.8930\n",
      "Epoch 50/100\n",
      "10685/10685 [==============================] - 1s 97us/step - loss: 0.2814 - accuracy: 0.9049 - val_loss: 0.2968 - val_accuracy: 0.8930\n",
      "Epoch 51/100\n",
      "10685/10685 [==============================] - 1s 70us/step - loss: 0.2814 - accuracy: 0.9050 - val_loss: 0.2968 - val_accuracy: 0.8930\n",
      "Epoch 52/100\n",
      "10685/10685 [==============================] - 1s 62us/step - loss: 0.2813 - accuracy: 0.9047 - val_loss: 0.2968 - val_accuracy: 0.8930\n",
      "Epoch 53/100\n",
      "10685/10685 [==============================] - 1s 71us/step - loss: 0.2813 - accuracy: 0.9049 - val_loss: 0.2967 - val_accuracy: 0.8930\n",
      "Epoch 54/100\n",
      "10685/10685 [==============================] - 1s 71us/step - loss: 0.2812 - accuracy: 0.9048 - val_loss: 0.2967 - val_accuracy: 0.8930\n",
      "Epoch 55/100\n",
      "10685/10685 [==============================] - 1s 62us/step - loss: 0.2812 - accuracy: 0.9049 - val_loss: 0.2967 - val_accuracy: 0.8930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "10685/10685 [==============================] - 1s 59us/step - loss: 0.2812 - accuracy: 0.9051 - val_loss: 0.2967 - val_accuracy: 0.8930\n",
      "Epoch 57/100\n",
      "10685/10685 [==============================] - 1s 78us/step - loss: 0.2811 - accuracy: 0.9049 - val_loss: 0.2967 - val_accuracy: 0.8930\n",
      "Epoch 58/100\n",
      "10685/10685 [==============================] - 1s 76us/step - loss: 0.2811 - accuracy: 0.9050 - val_loss: 0.2967 - val_accuracy: 0.8930\n",
      "Epoch 59/100\n",
      "10685/10685 [==============================] - 1s 82us/step - loss: 0.2811 - accuracy: 0.9050 - val_loss: 0.2966 - val_accuracy: 0.8930\n",
      "Epoch 60/100\n",
      "10685/10685 [==============================] - 1s 75us/step - loss: 0.2810 - accuracy: 0.9048 - val_loss: 0.2966 - val_accuracy: 0.8930\n",
      "Epoch 61/100\n",
      "10685/10685 [==============================] - 1s 58us/step - loss: 0.2810 - accuracy: 0.9052 - val_loss: 0.2966 - val_accuracy: 0.8930\n",
      "Epoch 62/100\n",
      "10685/10685 [==============================] - 1s 65us/step - loss: 0.2810 - accuracy: 0.9052 - val_loss: 0.2965 - val_accuracy: 0.8930\n",
      "Epoch 63/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2809 - accuracy: 0.9048 - val_loss: 0.2966 - val_accuracy: 0.8930\n",
      "Epoch 64/100\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.2809 - accuracy: 0.9052 - val_loss: 0.2965 - val_accuracy: 0.8930\n",
      "Epoch 65/100\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.2809 - accuracy: 0.9051 - val_loss: 0.2965 - val_accuracy: 0.8930\n",
      "Epoch 66/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2808 - accuracy: 0.9051 - val_loss: 0.2965 - val_accuracy: 0.8930\n",
      "Epoch 67/100\n",
      "10685/10685 [==============================] - 1s 59us/step - loss: 0.2808 - accuracy: 0.9052 - val_loss: 0.2965 - val_accuracy: 0.8930\n",
      "Epoch 68/100\n",
      "10685/10685 [==============================] - 1s 54us/step - loss: 0.2808 - accuracy: 0.9050 - val_loss: 0.2965 - val_accuracy: 0.8930\n",
      "Epoch 69/100\n",
      "10685/10685 [==============================] - 1s 60us/step - loss: 0.2807 - accuracy: 0.9052 - val_loss: 0.2964 - val_accuracy: 0.8930\n",
      "Epoch 70/100\n",
      "10685/10685 [==============================] - 1s 62us/step - loss: 0.2807 - accuracy: 0.9048 - val_loss: 0.2964 - val_accuracy: 0.8930\n",
      "Epoch 71/100\n",
      "10685/10685 [==============================] - 1s 62us/step - loss: 0.2806 - accuracy: 0.9048 - val_loss: 0.2964 - val_accuracy: 0.8930\n",
      "Epoch 72/100\n",
      "10685/10685 [==============================] - 1s 65us/step - loss: 0.2806 - accuracy: 0.9053 - val_loss: 0.2964 - val_accuracy: 0.8930\n",
      "Epoch 73/100\n",
      "10685/10685 [==============================] - 1s 64us/step - loss: 0.2806 - accuracy: 0.9049 - val_loss: 0.2964 - val_accuracy: 0.8930\n",
      "Epoch 74/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2805 - accuracy: 0.9052 - val_loss: 0.2964 - val_accuracy: 0.8937\n",
      "Epoch 75/100\n",
      "10685/10685 [==============================] - 1s 57us/step - loss: 0.2805 - accuracy: 0.9049 - val_loss: 0.2963 - val_accuracy: 0.8937\n",
      "Epoch 76/100\n",
      "10685/10685 [==============================] - 1s 59us/step - loss: 0.2805 - accuracy: 0.9049 - val_loss: 0.2963 - val_accuracy: 0.8937\n",
      "Epoch 77/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2804 - accuracy: 0.9049 - val_loss: 0.2963 - val_accuracy: 0.8937\n",
      "Epoch 78/100\n",
      "10685/10685 [==============================] - 1s 57us/step - loss: 0.2804 - accuracy: 0.9050 - val_loss: 0.2963 - val_accuracy: 0.8937\n",
      "Epoch 79/100\n",
      "10685/10685 [==============================] - 1s 63us/step - loss: 0.2804 - accuracy: 0.9050 - val_loss: 0.2963 - val_accuracy: 0.8937\n",
      "Epoch 80/100\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.2803 - accuracy: 0.9050 - val_loss: 0.2962 - val_accuracy: 0.8937\n",
      "Epoch 81/100\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.2803 - accuracy: 0.9049 - val_loss: 0.2962 - val_accuracy: 0.8937\n",
      "Epoch 82/100\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.2803 - accuracy: 0.9048 - val_loss: 0.2962 - val_accuracy: 0.8937\n",
      "Epoch 83/100\n",
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.2802 - accuracy: 0.9053 - val_loss: 0.2962 - val_accuracy: 0.8937\n",
      "Epoch 84/100\n",
      "10685/10685 [==============================] - 1s 60us/step - loss: 0.2802 - accuracy: 0.9051 - val_loss: 0.2962 - val_accuracy: 0.8937\n",
      "Epoch 85/100\n",
      "10685/10685 [==============================] - 1s 52us/step - loss: 0.2802 - accuracy: 0.9050 - val_loss: 0.2962 - val_accuracy: 0.8937\n",
      "Epoch 86/100\n",
      "10685/10685 [==============================] - 1s 52us/step - loss: 0.2801 - accuracy: 0.9051 - val_loss: 0.2961 - val_accuracy: 0.8937\n",
      "Epoch 87/100\n",
      "10685/10685 [==============================] - 1s 52us/step - loss: 0.2801 - accuracy: 0.9051 - val_loss: 0.2961 - val_accuracy: 0.8937\n",
      "Epoch 88/100\n",
      "10685/10685 [==============================] - 1s 60us/step - loss: 0.2801 - accuracy: 0.9049 - val_loss: 0.2961 - val_accuracy: 0.8937\n",
      "Epoch 89/100\n",
      "10685/10685 [==============================] - 1s 62us/step - loss: 0.2800 - accuracy: 0.9050 - val_loss: 0.2961 - val_accuracy: 0.8930\n",
      "Epoch 90/100\n",
      "10685/10685 [==============================] - 1s 54us/step - loss: 0.2800 - accuracy: 0.9050 - val_loss: 0.2961 - val_accuracy: 0.8937\n",
      "Epoch 91/100\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.2800 - accuracy: 0.9052 - val_loss: 0.2960 - val_accuracy: 0.8930\n",
      "Epoch 92/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2799 - accuracy: 0.9050 - val_loss: 0.2960 - val_accuracy: 0.8930\n",
      "Epoch 93/100\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2799 - accuracy: 0.9051 - val_loss: 0.2960 - val_accuracy: 0.8937\n",
      "Epoch 94/100\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2799 - accuracy: 0.9053 - val_loss: 0.2960 - val_accuracy: 0.8937\n",
      "Epoch 95/100\n",
      "10685/10685 [==============================] - 1s 58us/step - loss: 0.2798 - accuracy: 0.9054 - val_loss: 0.2959 - val_accuracy: 0.8937\n",
      "Epoch 96/100\n",
      "10685/10685 [==============================] - 1s 60us/step - loss: 0.2798 - accuracy: 0.9049 - val_loss: 0.2960 - val_accuracy: 0.8930\n",
      "Epoch 97/100\n",
      "10685/10685 [==============================] - 1s 61us/step - loss: 0.2798 - accuracy: 0.9049 - val_loss: 0.2960 - val_accuracy: 0.8930\n",
      "Epoch 98/100\n",
      "10685/10685 [==============================] - 1s 60us/step - loss: 0.2797 - accuracy: 0.9053 - val_loss: 0.2959 - val_accuracy: 0.8930\n",
      "Epoch 99/100\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.2797 - accuracy: 0.9052 - val_loss: 0.2959 - val_accuracy: 0.8930\n",
      "Epoch 100/100\n",
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.2797 - accuracy: 0.9051 - val_loss: 0.2959 - val_accuracy: 0.8930\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train_one_hot,\n",
    "                  validation_data=(X_val, y_val_one_hot), \n",
    "                  epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 79. 多層ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10685 samples, validate on 1336 samples\n",
      "Epoch 1/500\n",
      "10685/10685 [==============================] - 1s 119us/step - loss: 1.2106 - accuracy: 0.5332 - val_loss: 1.1005 - val_accuracy: 0.6841\n",
      "Epoch 2/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 1.0309 - accuracy: 0.7394 - val_loss: 0.9879 - val_accuracy: 0.7545\n",
      "Epoch 3/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.9290 - accuracy: 0.7647 - val_loss: 0.8908 - val_accuracy: 0.7695\n",
      "Epoch 4/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.8391 - accuracy: 0.7726 - val_loss: 0.8058 - val_accuracy: 0.7725\n",
      "Epoch 5/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.7640 - accuracy: 0.7758 - val_loss: 0.7374 - val_accuracy: 0.7762\n",
      "Epoch 6/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.7055 - accuracy: 0.7775 - val_loss: 0.6855 - val_accuracy: 0.7769\n",
      "Epoch 7/500\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.6613 - accuracy: 0.7787 - val_loss: 0.6457 - val_accuracy: 0.7769\n",
      "Epoch 8/500\n",
      "10685/10685 [==============================] - 1s 54us/step - loss: 0.6274 - accuracy: 0.7800 - val_loss: 0.6151 - val_accuracy: 0.7792\n",
      "Epoch 9/500\n",
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.6009 - accuracy: 0.7815 - val_loss: 0.5911 - val_accuracy: 0.7792\n",
      "Epoch 10/500\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.5797 - accuracy: 0.7830 - val_loss: 0.5709 - val_accuracy: 0.7829\n",
      "Epoch 11/500\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.5619 - accuracy: 0.7872 - val_loss: 0.5542 - val_accuracy: 0.7852\n",
      "Epoch 12/500\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.5466 - accuracy: 0.7902 - val_loss: 0.5394 - val_accuracy: 0.7927\n",
      "Epoch 13/500\n",
      "10685/10685 [==============================] - 1s 57us/step - loss: 0.5333 - accuracy: 0.7960 - val_loss: 0.5266 - val_accuracy: 0.7964\n",
      "Epoch 14/500\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.5213 - accuracy: 0.8009 - val_loss: 0.5150 - val_accuracy: 0.8009\n",
      "Epoch 15/500\n",
      "10685/10685 [==============================] - 1s 76us/step - loss: 0.5104 - accuracy: 0.8059 - val_loss: 0.5045 - val_accuracy: 0.8054\n",
      "Epoch 16/500\n",
      "10685/10685 [==============================] - 1s 63us/step - loss: 0.5003 - accuracy: 0.8117 - val_loss: 0.4946 - val_accuracy: 0.8106\n",
      "Epoch 17/500\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.4909 - accuracy: 0.8171 - val_loss: 0.4854 - val_accuracy: 0.8174\n",
      "Epoch 18/500\n",
      "10685/10685 [==============================] - 0s 47us/step - loss: 0.4820 - accuracy: 0.8221 - val_loss: 0.4767 - val_accuracy: 0.8196\n",
      "Epoch 19/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.4735 - accuracy: 0.8267 - val_loss: 0.4685 - val_accuracy: 0.8219\n",
      "Epoch 20/500\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.4654 - accuracy: 0.8311 - val_loss: 0.4603 - val_accuracy: 0.8256\n",
      "Epoch 21/500\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.4575 - accuracy: 0.8372 - val_loss: 0.4534 - val_accuracy: 0.8286\n",
      "Epoch 22/500\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.4501 - accuracy: 0.8414 - val_loss: 0.4463 - val_accuracy: 0.8293\n",
      "Epoch 23/500\n",
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.4430 - accuracy: 0.8437 - val_loss: 0.4390 - val_accuracy: 0.8338\n",
      "Epoch 24/500\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.4360 - accuracy: 0.8468 - val_loss: 0.4329 - val_accuracy: 0.8346\n",
      "Epoch 25/500\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.4295 - accuracy: 0.8500 - val_loss: 0.4259 - val_accuracy: 0.8428\n",
      "Epoch 26/500\n",
      "10685/10685 [==============================] - 1s 65us/step - loss: 0.4230 - accuracy: 0.8536 - val_loss: 0.4199 - val_accuracy: 0.8466\n",
      "Epoch 27/500\n",
      "10685/10685 [==============================] - 1s 57us/step - loss: 0.4170 - accuracy: 0.8557 - val_loss: 0.4146 - val_accuracy: 0.8503\n",
      "Epoch 28/500\n",
      "10685/10685 [==============================] - 1s 64us/step - loss: 0.4112 - accuracy: 0.8576 - val_loss: 0.4088 - val_accuracy: 0.8540\n",
      "Epoch 29/500\n",
      "10685/10685 [==============================] - 1s 52us/step - loss: 0.4056 - accuracy: 0.8601 - val_loss: 0.4036 - val_accuracy: 0.8555\n",
      "Epoch 30/500\n",
      "10685/10685 [==============================] - 1s 58us/step - loss: 0.4002 - accuracy: 0.8625 - val_loss: 0.3982 - val_accuracy: 0.8548\n",
      "Epoch 31/500\n",
      "10685/10685 [==============================] - 1s 54us/step - loss: 0.3951 - accuracy: 0.8644 - val_loss: 0.3938 - val_accuracy: 0.8585\n",
      "Epoch 32/500\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.3902 - accuracy: 0.8663 - val_loss: 0.3887 - val_accuracy: 0.8593\n",
      "Epoch 33/500\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.3856 - accuracy: 0.8679 - val_loss: 0.3846 - val_accuracy: 0.8623\n",
      "Epoch 34/500\n",
      "10685/10685 [==============================] - 0s 47us/step - loss: 0.3811 - accuracy: 0.8702 - val_loss: 0.3804 - val_accuracy: 0.8630\n",
      "Epoch 35/500\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.3769 - accuracy: 0.8719 - val_loss: 0.3764 - val_accuracy: 0.8675\n",
      "Epoch 36/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.3728 - accuracy: 0.8753 - val_loss: 0.3735 - val_accuracy: 0.8630\n",
      "Epoch 37/500\n",
      "10685/10685 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 0.87 - 0s 38us/step - loss: 0.3691 - accuracy: 0.8741 - val_loss: 0.3697 - val_accuracy: 0.8675\n",
      "Epoch 38/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.3654 - accuracy: 0.8766 - val_loss: 0.3662 - val_accuracy: 0.8705\n",
      "Epoch 39/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.3621 - accuracy: 0.8763 - val_loss: 0.3630 - val_accuracy: 0.8698\n",
      "Epoch 40/500\n",
      "10685/10685 [==============================] - 1s 52us/step - loss: 0.3586 - accuracy: 0.8785 - val_loss: 0.3596 - val_accuracy: 0.8698\n",
      "Epoch 41/500\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3555 - accuracy: 0.8801 - val_loss: 0.3573 - val_accuracy: 0.8698\n",
      "Epoch 42/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.3524 - accuracy: 0.8808 - val_loss: 0.3540 - val_accuracy: 0.8713\n",
      "Epoch 43/500\n",
      "10685/10685 [==============================] - 0s 34us/step - loss: 0.3496 - accuracy: 0.8828 - val_loss: 0.3522 - val_accuracy: 0.8720\n",
      "Epoch 44/500\n",
      "10685/10685 [==============================] - 0s 36us/step - loss: 0.3469 - accuracy: 0.8825 - val_loss: 0.3497 - val_accuracy: 0.8713\n",
      "Epoch 45/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.3443 - accuracy: 0.8846 - val_loss: 0.3477 - val_accuracy: 0.8728\n",
      "Epoch 46/500\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.3418 - accuracy: 0.8847 - val_loss: 0.3447 - val_accuracy: 0.8735\n",
      "Epoch 47/500\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.3395 - accuracy: 0.8856 - val_loss: 0.3423 - val_accuracy: 0.8743\n",
      "Epoch 48/500\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.3372 - accuracy: 0.8869 - val_loss: 0.3407 - val_accuracy: 0.8757\n",
      "Epoch 49/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.3351 - accuracy: 0.8879 - val_loss: 0.3396 - val_accuracy: 0.8750\n",
      "Epoch 50/500\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.3331 - accuracy: 0.8881 - val_loss: 0.3372 - val_accuracy: 0.8765\n",
      "Epoch 51/500\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.3309 - accuracy: 0.8885 - val_loss: 0.3347 - val_accuracy: 0.8795\n",
      "Epoch 52/500\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.3291 - accuracy: 0.8895 - val_loss: 0.3336 - val_accuracy: 0.8787\n",
      "Epoch 53/500\n",
      "10685/10685 [==============================] - 1s 71us/step - loss: 0.3272 - accuracy: 0.8900 - val_loss: 0.3334 - val_accuracy: 0.8780\n",
      "Epoch 54/500\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.3255 - accuracy: 0.8906 - val_loss: 0.3318 - val_accuracy: 0.8787\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10685/10685 [==============================] - 1s 54us/step - loss: 0.3239 - accuracy: 0.8899 - val_loss: 0.3299 - val_accuracy: 0.8817\n",
      "Epoch 56/500\n",
      "10685/10685 [==============================] - 1s 54us/step - loss: 0.3222 - accuracy: 0.8909 - val_loss: 0.3280 - val_accuracy: 0.8795\n",
      "Epoch 57/500\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.3207 - accuracy: 0.8916 - val_loss: 0.3260 - val_accuracy: 0.8817\n",
      "Epoch 58/500\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.3192 - accuracy: 0.8913 - val_loss: 0.3248 - val_accuracy: 0.8825\n",
      "Epoch 59/500\n",
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.3176 - accuracy: 0.8926 - val_loss: 0.3240 - val_accuracy: 0.8840\n",
      "Epoch 60/500\n",
      "10685/10685 [==============================] - 1s 58us/step - loss: 0.3164 - accuracy: 0.8932 - val_loss: 0.3228 - val_accuracy: 0.8840\n",
      "Epoch 61/500\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3151 - accuracy: 0.8930 - val_loss: 0.3221 - val_accuracy: 0.8847\n",
      "Epoch 62/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.3138 - accuracy: 0.8933 - val_loss: 0.3211 - val_accuracy: 0.8847\n",
      "Epoch 63/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.3124 - accuracy: 0.8944 - val_loss: 0.3196 - val_accuracy: 0.8870\n",
      "Epoch 64/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.3112 - accuracy: 0.8936 - val_loss: 0.3190 - val_accuracy: 0.8840\n",
      "Epoch 65/500\n",
      "10685/10685 [==============================] - 1s 61us/step - loss: 0.3100 - accuracy: 0.8941 - val_loss: 0.3183 - val_accuracy: 0.8877\n",
      "Epoch 66/500\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.3087 - accuracy: 0.8950 - val_loss: 0.3185 - val_accuracy: 0.8825\n",
      "Epoch 67/500\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.3077 - accuracy: 0.8946 - val_loss: 0.3159 - val_accuracy: 0.8877\n",
      "Epoch 68/500\n",
      "10685/10685 [==============================] - 1s 54us/step - loss: 0.3068 - accuracy: 0.8947 - val_loss: 0.3159 - val_accuracy: 0.8847\n",
      "Epoch 69/500\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.3056 - accuracy: 0.8950 - val_loss: 0.3159 - val_accuracy: 0.8892\n",
      "Epoch 70/500\n",
      "10685/10685 [==============================] - 1s 76us/step - loss: 0.3048 - accuracy: 0.8954 - val_loss: 0.3138 - val_accuracy: 0.8900\n",
      "Epoch 71/500\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.3035 - accuracy: 0.8956 - val_loss: 0.3127 - val_accuracy: 0.8877\n",
      "Epoch 72/500\n",
      "10685/10685 [==============================] - 1s 67us/step - loss: 0.3027 - accuracy: 0.8956 - val_loss: 0.3132 - val_accuracy: 0.8847\n",
      "Epoch 73/500\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.3018 - accuracy: 0.8960 - val_loss: 0.3124 - val_accuracy: 0.8885\n",
      "Epoch 74/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.3007 - accuracy: 0.8965 - val_loss: 0.3105 - val_accuracy: 0.8870\n",
      "Epoch 75/500\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.3001 - accuracy: 0.8963 - val_loss: 0.3102 - val_accuracy: 0.8877\n",
      "Epoch 76/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2991 - accuracy: 0.8968 - val_loss: 0.3102 - val_accuracy: 0.8885\n",
      "Epoch 77/500\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.2981 - accuracy: 0.8969 - val_loss: 0.3098 - val_accuracy: 0.8900\n",
      "Epoch 78/500\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2974 - accuracy: 0.8980 - val_loss: 0.3081 - val_accuracy: 0.8877\n",
      "Epoch 79/500\n",
      "10685/10685 [==============================] - 1s 65us/step - loss: 0.2968 - accuracy: 0.8966 - val_loss: 0.3087 - val_accuracy: 0.8862\n",
      "Epoch 80/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2959 - accuracy: 0.8974 - val_loss: 0.3076 - val_accuracy: 0.8870\n",
      "Epoch 81/500\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.2950 - accuracy: 0.8979 - val_loss: 0.3072 - val_accuracy: 0.8862\n",
      "Epoch 82/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2943 - accuracy: 0.8981 - val_loss: 0.3060 - val_accuracy: 0.8892\n",
      "Epoch 83/500\n",
      "10685/10685 [==============================] - 1s 59us/step - loss: 0.2936 - accuracy: 0.8982 - val_loss: 0.3059 - val_accuracy: 0.8885\n",
      "Epoch 84/500\n",
      "10685/10685 [==============================] - 1s 70us/step - loss: 0.2928 - accuracy: 0.8985 - val_loss: 0.3061 - val_accuracy: 0.8907\n",
      "Epoch 85/500\n",
      "10685/10685 [==============================] - 1s 70us/step - loss: 0.2922 - accuracy: 0.8987 - val_loss: 0.3056 - val_accuracy: 0.8900\n",
      "Epoch 86/500\n",
      "10685/10685 [==============================] - 1s 68us/step - loss: 0.2914 - accuracy: 0.8993 - val_loss: 0.3051 - val_accuracy: 0.8877\n",
      "Epoch 87/500\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.2908 - accuracy: 0.8987 - val_loss: 0.3044 - val_accuracy: 0.8877\n",
      "Epoch 88/500\n",
      "10685/10685 [==============================] - 1s 65us/step - loss: 0.2902 - accuracy: 0.8993 - val_loss: 0.3043 - val_accuracy: 0.8870\n",
      "Epoch 89/500\n",
      "10685/10685 [==============================] - 1s 70us/step - loss: 0.2896 - accuracy: 0.8991 - val_loss: 0.3029 - val_accuracy: 0.8915\n",
      "Epoch 90/500\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.2888 - accuracy: 0.8999 - val_loss: 0.3035 - val_accuracy: 0.8870\n",
      "Epoch 91/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2884 - accuracy: 0.8987 - val_loss: 0.3021 - val_accuracy: 0.8915\n",
      "Epoch 92/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2878 - accuracy: 0.8991 - val_loss: 0.3022 - val_accuracy: 0.8900\n",
      "Epoch 93/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2871 - accuracy: 0.8998 - val_loss: 0.3017 - val_accuracy: 0.8907\n",
      "Epoch 94/500\n",
      "10685/10685 [==============================] - 0s 36us/step - loss: 0.2865 - accuracy: 0.9002 - val_loss: 0.3016 - val_accuracy: 0.8915\n",
      "Epoch 95/500\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2859 - accuracy: 0.8998 - val_loss: 0.3010 - val_accuracy: 0.8922\n",
      "Epoch 96/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2853 - accuracy: 0.9013 - val_loss: 0.3008 - val_accuracy: 0.8892\n",
      "Epoch 97/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2847 - accuracy: 0.9009 - val_loss: 0.3010 - val_accuracy: 0.8915\n",
      "Epoch 98/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2843 - accuracy: 0.9007 - val_loss: 0.3009 - val_accuracy: 0.8907\n",
      "Epoch 99/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2836 - accuracy: 0.9007 - val_loss: 0.3004 - val_accuracy: 0.8915\n",
      "Epoch 100/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2831 - accuracy: 0.9005 - val_loss: 0.2993 - val_accuracy: 0.8922\n",
      "Epoch 101/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2827 - accuracy: 0.9015 - val_loss: 0.2994 - val_accuracy: 0.8915\n",
      "Epoch 102/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2820 - accuracy: 0.9015 - val_loss: 0.3001 - val_accuracy: 0.8922\n",
      "Epoch 103/500\n",
      "10685/10685 [==============================] - 1s 58us/step - loss: 0.2816 - accuracy: 0.9012 - val_loss: 0.2986 - val_accuracy: 0.8915\n",
      "Epoch 104/500\n",
      "10685/10685 [==============================] - 1s 60us/step - loss: 0.2811 - accuracy: 0.9017 - val_loss: 0.2995 - val_accuracy: 0.8922\n",
      "Epoch 105/500\n",
      "10685/10685 [==============================] - 1s 61us/step - loss: 0.2805 - accuracy: 0.9009 - val_loss: 0.2980 - val_accuracy: 0.8937\n",
      "Epoch 106/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2801 - accuracy: 0.9019 - val_loss: 0.2993 - val_accuracy: 0.8907\n",
      "Epoch 107/500\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.2797 - accuracy: 0.9028 - val_loss: 0.2988 - val_accuracy: 0.8937\n",
      "Epoch 108/500\n",
      "10685/10685 [==============================] - 1s 60us/step - loss: 0.2792 - accuracy: 0.9028 - val_loss: 0.2972 - val_accuracy: 0.8930\n",
      "Epoch 109/500\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2787 - accuracy: 0.9019 - val_loss: 0.2983 - val_accuracy: 0.8952\n",
      "Epoch 110/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2782 - accuracy: 0.9039 - val_loss: 0.2981 - val_accuracy: 0.8937\n",
      "Epoch 111/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2778 - accuracy: 0.9032 - val_loss: 0.2974 - val_accuracy: 0.8937\n",
      "Epoch 112/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2775 - accuracy: 0.9028 - val_loss: 0.2961 - val_accuracy: 0.8937\n",
      "Epoch 113/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2770 - accuracy: 0.9033 - val_loss: 0.2961 - val_accuracy: 0.8937\n",
      "Epoch 114/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2764 - accuracy: 0.9031 - val_loss: 0.2960 - val_accuracy: 0.8945\n",
      "Epoch 115/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2760 - accuracy: 0.9041 - val_loss: 0.2974 - val_accuracy: 0.8922\n",
      "Epoch 116/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2757 - accuracy: 0.9048 - val_loss: 0.2967 - val_accuracy: 0.8930\n",
      "Epoch 117/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2754 - accuracy: 0.9044 - val_loss: 0.2958 - val_accuracy: 0.8945\n",
      "Epoch 118/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2750 - accuracy: 0.9045 - val_loss: 0.2958 - val_accuracy: 0.8945\n",
      "Epoch 119/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2744 - accuracy: 0.9044 - val_loss: 0.2958 - val_accuracy: 0.8967\n",
      "Epoch 120/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2742 - accuracy: 0.9052 - val_loss: 0.2958 - val_accuracy: 0.8945\n",
      "Epoch 121/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2737 - accuracy: 0.9053 - val_loss: 0.2961 - val_accuracy: 0.8937\n",
      "Epoch 122/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2733 - accuracy: 0.9054 - val_loss: 0.2953 - val_accuracy: 0.8967\n",
      "Epoch 123/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2729 - accuracy: 0.9051 - val_loss: 0.2944 - val_accuracy: 0.8952\n",
      "Epoch 124/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2725 - accuracy: 0.9050 - val_loss: 0.2954 - val_accuracy: 0.8967\n",
      "Epoch 125/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2723 - accuracy: 0.9055 - val_loss: 0.2949 - val_accuracy: 0.8975\n",
      "Epoch 126/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2717 - accuracy: 0.9058 - val_loss: 0.2955 - val_accuracy: 0.8975\n",
      "Epoch 127/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2716 - accuracy: 0.9055 - val_loss: 0.2956 - val_accuracy: 0.8982\n",
      "Epoch 128/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2712 - accuracy: 0.9055 - val_loss: 0.2946 - val_accuracy: 0.8967\n",
      "Epoch 129/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2708 - accuracy: 0.9058 - val_loss: 0.2937 - val_accuracy: 0.8960\n",
      "Epoch 130/500\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2704 - accuracy: 0.9063 - val_loss: 0.2931 - val_accuracy: 0.8930\n",
      "Epoch 131/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2702 - accuracy: 0.9063 - val_loss: 0.2939 - val_accuracy: 0.8967\n",
      "Epoch 132/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2696 - accuracy: 0.9063 - val_loss: 0.2946 - val_accuracy: 0.8975\n",
      "Epoch 133/500\n",
      "10685/10685 [==============================] - 0s 36us/step - loss: 0.2695 - accuracy: 0.9064 - val_loss: 0.2933 - val_accuracy: 0.8967\n",
      "Epoch 134/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2691 - accuracy: 0.9071 - val_loss: 0.2929 - val_accuracy: 0.8982\n",
      "Epoch 135/500\n",
      "10685/10685 [==============================] - 0s 33us/step - loss: 0.2688 - accuracy: 0.9068 - val_loss: 0.2933 - val_accuracy: 0.8982\n",
      "Epoch 136/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2684 - accuracy: 0.9061 - val_loss: 0.2930 - val_accuracy: 0.8967\n",
      "Epoch 137/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2681 - accuracy: 0.9074 - val_loss: 0.2933 - val_accuracy: 0.8975\n",
      "Epoch 138/500\n",
      "10685/10685 [==============================] - 0s 33us/step - loss: 0.2679 - accuracy: 0.9073 - val_loss: 0.2931 - val_accuracy: 0.8982\n",
      "Epoch 139/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2675 - accuracy: 0.9070 - val_loss: 0.2935 - val_accuracy: 0.8952\n",
      "Epoch 140/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2671 - accuracy: 0.9076 - val_loss: 0.2940 - val_accuracy: 0.9012\n",
      "Epoch 141/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2670 - accuracy: 0.9067 - val_loss: 0.2932 - val_accuracy: 0.9004\n",
      "Epoch 142/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2666 - accuracy: 0.9077 - val_loss: 0.2940 - val_accuracy: 0.9012\n",
      "Epoch 143/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2664 - accuracy: 0.9073 - val_loss: 0.2924 - val_accuracy: 0.8982\n",
      "Epoch 144/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2660 - accuracy: 0.9080 - val_loss: 0.2930 - val_accuracy: 0.8997\n",
      "Epoch 145/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2658 - accuracy: 0.9071 - val_loss: 0.2928 - val_accuracy: 0.8990\n",
      "Epoch 146/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2655 - accuracy: 0.9073 - val_loss: 0.2918 - val_accuracy: 0.8982\n",
      "Epoch 147/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2652 - accuracy: 0.9085 - val_loss: 0.2918 - val_accuracy: 0.8990\n",
      "Epoch 148/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2650 - accuracy: 0.9077 - val_loss: 0.2921 - val_accuracy: 0.8975\n",
      "Epoch 149/500\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.2647 - accuracy: 0.9080 - val_loss: 0.2924 - val_accuracy: 0.8982\n",
      "Epoch 150/500\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.2646 - accuracy: 0.9087 - val_loss: 0.2927 - val_accuracy: 0.8997\n",
      "Epoch 151/500\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.2641 - accuracy: 0.9083 - val_loss: 0.2916 - val_accuracy: 0.8975\n",
      "Epoch 152/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2638 - accuracy: 0.9086 - val_loss: 0.2925 - val_accuracy: 0.8982\n",
      "Epoch 153/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2636 - accuracy: 0.9078 - val_loss: 0.2922 - val_accuracy: 0.8990\n",
      "Epoch 154/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2633 - accuracy: 0.9081 - val_loss: 0.2928 - val_accuracy: 0.8982\n",
      "Epoch 155/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2630 - accuracy: 0.9088 - val_loss: 0.2924 - val_accuracy: 0.8967\n",
      "Epoch 156/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2629 - accuracy: 0.9085 - val_loss: 0.2921 - val_accuracy: 0.8960\n",
      "Epoch 157/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2627 - accuracy: 0.9087 - val_loss: 0.2911 - val_accuracy: 0.8975\n",
      "Epoch 158/500\n",
      "10685/10685 [==============================] - 0s 36us/step - loss: 0.2624 - accuracy: 0.9086 - val_loss: 0.2912 - val_accuracy: 0.8990\n",
      "Epoch 159/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2620 - accuracy: 0.9088 - val_loss: 0.2908 - val_accuracy: 0.8975\n",
      "Epoch 160/500\n",
      "10685/10685 [==============================] - 0s 34us/step - loss: 0.2620 - accuracy: 0.9091 - val_loss: 0.2911 - val_accuracy: 0.8982\n",
      "Epoch 161/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2616 - accuracy: 0.9086 - val_loss: 0.2906 - val_accuracy: 0.8952\n",
      "Epoch 162/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2615 - accuracy: 0.9091 - val_loss: 0.2916 - val_accuracy: 0.8990\n",
      "Epoch 163/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2612 - accuracy: 0.9094 - val_loss: 0.2923 - val_accuracy: 0.9004\n",
      "Epoch 164/500\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.2610 - accuracy: 0.9090 - val_loss: 0.2915 - val_accuracy: 0.8975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2607 - accuracy: 0.9093 - val_loss: 0.2909 - val_accuracy: 0.8975\n",
      "Epoch 166/500\n",
      "10685/10685 [==============================] - 1s 59us/step - loss: 0.2604 - accuracy: 0.9093 - val_loss: 0.2912 - val_accuracy: 0.8982\n",
      "Epoch 167/500\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.2603 - accuracy: 0.9093 - val_loss: 0.2908 - val_accuracy: 0.9004\n",
      "Epoch 168/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2601 - accuracy: 0.9098 - val_loss: 0.2925 - val_accuracy: 0.8997\n",
      "Epoch 169/500\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.2600 - accuracy: 0.9099 - val_loss: 0.2911 - val_accuracy: 0.8990\n",
      "Epoch 170/500\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2595 - accuracy: 0.9090 - val_loss: 0.2912 - val_accuracy: 0.8982\n",
      "Epoch 171/500\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.2594 - accuracy: 0.9085 - val_loss: 0.2906 - val_accuracy: 0.8975\n",
      "Epoch 172/500\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2593 - accuracy: 0.9098 - val_loss: 0.2915 - val_accuracy: 0.9004\n",
      "Epoch 173/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2591 - accuracy: 0.9096 - val_loss: 0.2908 - val_accuracy: 0.8990\n",
      "Epoch 174/500\n",
      "10685/10685 [==============================] - 0s 47us/step - loss: 0.2585 - accuracy: 0.9101 - val_loss: 0.2907 - val_accuracy: 0.8997\n",
      "Epoch 175/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2586 - accuracy: 0.9105 - val_loss: 0.2914 - val_accuracy: 0.9004\n",
      "Epoch 176/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2585 - accuracy: 0.9102 - val_loss: 0.2912 - val_accuracy: 0.8990\n",
      "Epoch 177/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2582 - accuracy: 0.9101 - val_loss: 0.2909 - val_accuracy: 0.8990\n",
      "Epoch 178/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2580 - accuracy: 0.9095 - val_loss: 0.2906 - val_accuracy: 0.8990\n",
      "Epoch 179/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2578 - accuracy: 0.9108 - val_loss: 0.2908 - val_accuracy: 0.8982\n",
      "Epoch 180/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2577 - accuracy: 0.9101 - val_loss: 0.2912 - val_accuracy: 0.8990\n",
      "Epoch 181/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2575 - accuracy: 0.9102 - val_loss: 0.2909 - val_accuracy: 0.8982\n",
      "Epoch 182/500\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.2573 - accuracy: 0.9105 - val_loss: 0.2921 - val_accuracy: 0.8997\n",
      "Epoch 183/500\n",
      "10685/10685 [==============================] - 1s 69us/step - loss: 0.2570 - accuracy: 0.9107 - val_loss: 0.2917 - val_accuracy: 0.8982\n",
      "Epoch 184/500\n",
      "10685/10685 [==============================] - 1s 65us/step - loss: 0.2569 - accuracy: 0.9103 - val_loss: 0.2906 - val_accuracy: 0.8967\n",
      "Epoch 185/500\n",
      "10685/10685 [==============================] - 1s 65us/step - loss: 0.2568 - accuracy: 0.9105 - val_loss: 0.2922 - val_accuracy: 0.8982\n",
      "Epoch 186/500\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2564 - accuracy: 0.9107 - val_loss: 0.2916 - val_accuracy: 0.9004\n",
      "Epoch 187/500\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.2563 - accuracy: 0.9113 - val_loss: 0.2910 - val_accuracy: 0.8982\n",
      "Epoch 188/500\n",
      "10685/10685 [==============================] - 1s 63us/step - loss: 0.2562 - accuracy: 0.9106 - val_loss: 0.2901 - val_accuracy: 0.8982\n",
      "Epoch 189/500\n",
      "10685/10685 [==============================] - 1s 63us/step - loss: 0.2561 - accuracy: 0.9112 - val_loss: 0.2912 - val_accuracy: 0.8997\n",
      "Epoch 190/500\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2558 - accuracy: 0.9104 - val_loss: 0.2902 - val_accuracy: 0.8975\n",
      "Epoch 191/500\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2555 - accuracy: 0.9118 - val_loss: 0.2919 - val_accuracy: 0.8997\n",
      "Epoch 192/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2556 - accuracy: 0.9111 - val_loss: 0.2920 - val_accuracy: 0.9004\n",
      "Epoch 193/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2552 - accuracy: 0.9110 - val_loss: 0.2909 - val_accuracy: 0.8967\n",
      "Epoch 194/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2551 - accuracy: 0.9117 - val_loss: 0.2922 - val_accuracy: 0.9004\n",
      "Epoch 195/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2549 - accuracy: 0.9113 - val_loss: 0.2916 - val_accuracy: 0.8960\n",
      "Epoch 196/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2550 - accuracy: 0.9111 - val_loss: 0.2916 - val_accuracy: 0.8990\n",
      "Epoch 197/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2547 - accuracy: 0.9106 - val_loss: 0.2906 - val_accuracy: 0.8990\n",
      "Epoch 198/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2544 - accuracy: 0.9119 - val_loss: 0.2905 - val_accuracy: 0.8990\n",
      "Epoch 199/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2542 - accuracy: 0.9119 - val_loss: 0.2918 - val_accuracy: 0.8997\n",
      "Epoch 200/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2542 - accuracy: 0.9111 - val_loss: 0.2902 - val_accuracy: 0.8990\n",
      "Epoch 201/500\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.2541 - accuracy: 0.9114 - val_loss: 0.2910 - val_accuracy: 0.8982\n",
      "Epoch 202/500\n",
      "10685/10685 [==============================] - 1s 54us/step - loss: 0.2537 - accuracy: 0.9114 - val_loss: 0.2915 - val_accuracy: 0.8990\n",
      "Epoch 203/500\n",
      "10685/10685 [==============================] - 1s 57us/step - loss: 0.2533 - accuracy: 0.9116 - val_loss: 0.2919 - val_accuracy: 0.9004\n",
      "Epoch 204/500\n",
      "10685/10685 [==============================] - 1s 57us/step - loss: 0.2535 - accuracy: 0.9124 - val_loss: 0.2903 - val_accuracy: 0.8990\n",
      "Epoch 205/500\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2534 - accuracy: 0.9115 - val_loss: 0.2917 - val_accuracy: 0.8990\n",
      "Epoch 206/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2532 - accuracy: 0.9120 - val_loss: 0.2907 - val_accuracy: 0.8990\n",
      "Epoch 207/500\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.2530 - accuracy: 0.9119 - val_loss: 0.2929 - val_accuracy: 0.8990\n",
      "Epoch 208/500\n",
      "10685/10685 [==============================] - 1s 54us/step - loss: 0.2531 - accuracy: 0.9126 - val_loss: 0.2918 - val_accuracy: 0.8990\n",
      "Epoch 209/500\n",
      "10685/10685 [==============================] - 1s 52us/step - loss: 0.2528 - accuracy: 0.9117 - val_loss: 0.2903 - val_accuracy: 0.8960\n",
      "Epoch 210/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2529 - accuracy: 0.9113 - val_loss: 0.2909 - val_accuracy: 0.8990\n",
      "Epoch 211/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2524 - accuracy: 0.9128 - val_loss: 0.2906 - val_accuracy: 0.8990\n",
      "Epoch 212/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2525 - accuracy: 0.9126 - val_loss: 0.2912 - val_accuracy: 0.8997\n",
      "Epoch 213/500\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2522 - accuracy: 0.9113 - val_loss: 0.2920 - val_accuracy: 0.9012\n",
      "Epoch 214/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2521 - accuracy: 0.9131 - val_loss: 0.2907 - val_accuracy: 0.8982\n",
      "Epoch 215/500\n",
      "10685/10685 [==============================] - 1s 59us/step - loss: 0.2519 - accuracy: 0.9119 - val_loss: 0.2917 - val_accuracy: 0.8997\n",
      "Epoch 216/500\n",
      "10685/10685 [==============================] - 1s 54us/step - loss: 0.2517 - accuracy: 0.9120 - val_loss: 0.2909 - val_accuracy: 0.8967\n",
      "Epoch 217/500\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2519 - accuracy: 0.9112 - val_loss: 0.2918 - val_accuracy: 0.8990\n",
      "Epoch 218/500\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.2514 - accuracy: 0.9127 - val_loss: 0.2920 - val_accuracy: 0.9004\n",
      "Epoch 219/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.2514 - accuracy: 0.9125 - val_loss: 0.2931 - val_accuracy: 0.8990\n",
      "Epoch 220/500\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.2513 - accuracy: 0.9129 - val_loss: 0.2915 - val_accuracy: 0.8967\n",
      "Epoch 221/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2511 - accuracy: 0.9122 - val_loss: 0.2912 - val_accuracy: 0.8990\n",
      "Epoch 222/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2510 - accuracy: 0.9119 - val_loss: 0.2905 - val_accuracy: 0.8982\n",
      "Epoch 223/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2510 - accuracy: 0.9117 - val_loss: 0.2912 - val_accuracy: 0.8997\n",
      "Epoch 224/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2508 - accuracy: 0.9126 - val_loss: 0.2912 - val_accuracy: 0.8997\n",
      "Epoch 225/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2507 - accuracy: 0.9129 - val_loss: 0.2928 - val_accuracy: 0.8997\n",
      "Epoch 226/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2505 - accuracy: 0.9131 - val_loss: 0.2912 - val_accuracy: 0.8982\n",
      "Epoch 227/500\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2505 - accuracy: 0.9125 - val_loss: 0.2927 - val_accuracy: 0.8997\n",
      "Epoch 228/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2502 - accuracy: 0.9117 - val_loss: 0.2910 - val_accuracy: 0.8982\n",
      "Epoch 229/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2502 - accuracy: 0.9120 - val_loss: 0.2918 - val_accuracy: 0.8997\n",
      "Epoch 230/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2502 - accuracy: 0.9126 - val_loss: 0.2917 - val_accuracy: 0.9012\n",
      "Epoch 231/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2500 - accuracy: 0.9134 - val_loss: 0.2910 - val_accuracy: 0.8982\n",
      "Epoch 232/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2499 - accuracy: 0.9131 - val_loss: 0.2923 - val_accuracy: 0.8997\n",
      "Epoch 233/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2496 - accuracy: 0.9127 - val_loss: 0.2929 - val_accuracy: 0.8997\n",
      "Epoch 234/500\n",
      "10685/10685 [==============================] - 0s 32us/step - loss: 0.2496 - accuracy: 0.9120 - val_loss: 0.2924 - val_accuracy: 0.9004\n",
      "Epoch 235/500\n",
      "10685/10685 [==============================] - 0s 33us/step - loss: 0.2494 - accuracy: 0.9134 - val_loss: 0.2926 - val_accuracy: 0.9004\n",
      "Epoch 236/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2493 - accuracy: 0.9137 - val_loss: 0.2920 - val_accuracy: 0.8975\n",
      "Epoch 237/500\n",
      "10685/10685 [==============================] - 0s 33us/step - loss: 0.2492 - accuracy: 0.9117 - val_loss: 0.2911 - val_accuracy: 0.8997\n",
      "Epoch 238/500\n",
      "10685/10685 [==============================] - 0s 33us/step - loss: 0.2493 - accuracy: 0.9120 - val_loss: 0.2910 - val_accuracy: 0.8990\n",
      "Epoch 239/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2491 - accuracy: 0.9125 - val_loss: 0.2926 - val_accuracy: 0.9012\n",
      "Epoch 240/500\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2490 - accuracy: 0.9129 - val_loss: 0.2924 - val_accuracy: 0.8990\n",
      "Epoch 241/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2488 - accuracy: 0.9141 - val_loss: 0.2918 - val_accuracy: 0.8997\n",
      "Epoch 242/500\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.2487 - accuracy: 0.9131 - val_loss: 0.2922 - val_accuracy: 0.9012\n",
      "Epoch 243/500\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2486 - accuracy: 0.9132 - val_loss: 0.2929 - val_accuracy: 0.9019\n",
      "Epoch 244/500\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2485 - accuracy: 0.9136 - val_loss: 0.2923 - val_accuracy: 0.9012\n",
      "Epoch 245/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2484 - accuracy: 0.9129 - val_loss: 0.2935 - val_accuracy: 0.8990\n",
      "Epoch 246/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2483 - accuracy: 0.9133 - val_loss: 0.2921 - val_accuracy: 0.8997\n",
      "Epoch 247/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2483 - accuracy: 0.9130 - val_loss: 0.2922 - val_accuracy: 0.9004\n",
      "Epoch 248/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2482 - accuracy: 0.9133 - val_loss: 0.2925 - val_accuracy: 0.9012\n",
      "Epoch 249/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2479 - accuracy: 0.9137 - val_loss: 0.2925 - val_accuracy: 0.9012\n",
      "Epoch 250/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2479 - accuracy: 0.9131 - val_loss: 0.2937 - val_accuracy: 0.8997\n",
      "Epoch 251/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2477 - accuracy: 0.9130 - val_loss: 0.2919 - val_accuracy: 0.9004\n",
      "Epoch 252/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2477 - accuracy: 0.9141 - val_loss: 0.2922 - val_accuracy: 0.9034\n",
      "Epoch 253/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2477 - accuracy: 0.9137 - val_loss: 0.2916 - val_accuracy: 0.9004\n",
      "Epoch 254/500\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2475 - accuracy: 0.9138 - val_loss: 0.2928 - val_accuracy: 0.9012\n",
      "Epoch 255/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2475 - accuracy: 0.9132 - val_loss: 0.2921 - val_accuracy: 0.8997\n",
      "Epoch 256/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2473 - accuracy: 0.9137 - val_loss: 0.2921 - val_accuracy: 0.8982\n",
      "Epoch 257/500\n",
      "10685/10685 [==============================] - 0s 34us/step - loss: 0.2471 - accuracy: 0.9146 - val_loss: 0.2926 - val_accuracy: 0.8997\n",
      "Epoch 258/500\n",
      "10685/10685 [==============================] - 0s 36us/step - loss: 0.2472 - accuracy: 0.9139 - val_loss: 0.2940 - val_accuracy: 0.9019\n",
      "Epoch 259/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2471 - accuracy: 0.9138 - val_loss: 0.2923 - val_accuracy: 0.9012\n",
      "Epoch 260/500\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.2471 - accuracy: 0.9140 - val_loss: 0.2926 - val_accuracy: 0.9019\n",
      "Epoch 261/500\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2469 - accuracy: 0.9136 - val_loss: 0.2933 - val_accuracy: 0.8997\n",
      "Epoch 262/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2466 - accuracy: 0.9146 - val_loss: 0.2927 - val_accuracy: 0.9034\n",
      "Epoch 263/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2466 - accuracy: 0.9135 - val_loss: 0.2931 - val_accuracy: 0.9027\n",
      "Epoch 264/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2465 - accuracy: 0.9136 - val_loss: 0.2928 - val_accuracy: 0.9034\n",
      "Epoch 265/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2465 - accuracy: 0.9135 - val_loss: 0.2935 - val_accuracy: 0.9004\n",
      "Epoch 266/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2462 - accuracy: 0.9134 - val_loss: 0.2931 - val_accuracy: 0.9019\n",
      "Epoch 267/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2464 - accuracy: 0.9138 - val_loss: 0.2924 - val_accuracy: 0.9012\n",
      "Epoch 268/500\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.2462 - accuracy: 0.9157 - val_loss: 0.2928 - val_accuracy: 0.8982\n",
      "Epoch 269/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2463 - accuracy: 0.9137 - val_loss: 0.2944 - val_accuracy: 0.8990\n",
      "Epoch 270/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2461 - accuracy: 0.9135 - val_loss: 0.2931 - val_accuracy: 0.9019\n",
      "Epoch 271/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2460 - accuracy: 0.9151 - val_loss: 0.2934 - val_accuracy: 0.9012\n",
      "Epoch 272/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2460 - accuracy: 0.9146 - val_loss: 0.2930 - val_accuracy: 0.9019\n",
      "Epoch 273/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2456 - accuracy: 0.9142 - val_loss: 0.2939 - val_accuracy: 0.9004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2457 - accuracy: 0.9152 - val_loss: 0.2938 - val_accuracy: 0.9019\n",
      "Epoch 275/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2456 - accuracy: 0.9147 - val_loss: 0.2950 - val_accuracy: 0.8982\n",
      "Epoch 276/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2454 - accuracy: 0.9132 - val_loss: 0.2946 - val_accuracy: 0.8997\n",
      "Epoch 277/500\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2456 - accuracy: 0.9153 - val_loss: 0.2949 - val_accuracy: 0.9004\n",
      "Epoch 278/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2456 - accuracy: 0.9150 - val_loss: 0.2945 - val_accuracy: 0.9004\n",
      "Epoch 279/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2455 - accuracy: 0.9146 - val_loss: 0.2949 - val_accuracy: 0.9012\n",
      "Epoch 280/500\n",
      "10685/10685 [==============================] - 1s 65us/step - loss: 0.2452 - accuracy: 0.9156 - val_loss: 0.2946 - val_accuracy: 0.9012\n",
      "Epoch 281/500\n",
      "10685/10685 [==============================] - 1s 65us/step - loss: 0.2451 - accuracy: 0.9139 - val_loss: 0.2933 - val_accuracy: 0.9004\n",
      "Epoch 282/500\n",
      "10685/10685 [==============================] - 1s 77us/step - loss: 0.2451 - accuracy: 0.9149 - val_loss: 0.2948 - val_accuracy: 0.8990\n",
      "Epoch 283/500\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.2452 - accuracy: 0.9149 - val_loss: 0.2934 - val_accuracy: 0.9019\n",
      "Epoch 284/500\n",
      "10685/10685 [==============================] - 1s 69us/step - loss: 0.2450 - accuracy: 0.9139 - val_loss: 0.2943 - val_accuracy: 0.9019\n",
      "Epoch 285/500\n",
      "10685/10685 [==============================] - 1s 77us/step - loss: 0.2447 - accuracy: 0.9146 - val_loss: 0.2945 - val_accuracy: 0.9012\n",
      "Epoch 286/500\n",
      "10685/10685 [==============================] - 1s 73us/step - loss: 0.2448 - accuracy: 0.9143 - val_loss: 0.2934 - val_accuracy: 0.9019\n",
      "Epoch 287/500\n",
      "10685/10685 [==============================] - 1s 75us/step - loss: 0.2447 - accuracy: 0.9147 - val_loss: 0.2941 - val_accuracy: 0.9004\n",
      "Epoch 288/500\n",
      "10685/10685 [==============================] - 1s 51us/step - loss: 0.2446 - accuracy: 0.9141 - val_loss: 0.2959 - val_accuracy: 0.8982\n",
      "Epoch 289/500\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.2447 - accuracy: 0.9149 - val_loss: 0.2940 - val_accuracy: 0.8990\n",
      "Epoch 290/500\n",
      "10685/10685 [==============================] - 1s 101us/step - loss: 0.2446 - accuracy: 0.9148 - val_loss: 0.2944 - val_accuracy: 0.8997\n",
      "Epoch 291/500\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2446 - accuracy: 0.9158 - val_loss: 0.2947 - val_accuracy: 0.9004\n",
      "Epoch 292/500\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.2444 - accuracy: 0.9148 - val_loss: 0.2937 - val_accuracy: 0.8997\n",
      "Epoch 293/500\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.2442 - accuracy: 0.9150 - val_loss: 0.2952 - val_accuracy: 0.8975\n",
      "Epoch 294/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2442 - accuracy: 0.9157 - val_loss: 0.2953 - val_accuracy: 0.8982\n",
      "Epoch 295/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2443 - accuracy: 0.9140 - val_loss: 0.2936 - val_accuracy: 0.9004\n",
      "Epoch 296/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2442 - accuracy: 0.9157 - val_loss: 0.2947 - val_accuracy: 0.8967\n",
      "Epoch 297/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2442 - accuracy: 0.9152 - val_loss: 0.2952 - val_accuracy: 0.8997\n",
      "Epoch 298/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2440 - accuracy: 0.9146 - val_loss: 0.2945 - val_accuracy: 0.8997\n",
      "Epoch 299/500\n",
      "10685/10685 [==============================] - 1s 62us/step - loss: 0.2440 - accuracy: 0.9156 - val_loss: 0.2945 - val_accuracy: 0.9004\n",
      "Epoch 300/500\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.2441 - accuracy: 0.9150 - val_loss: 0.2954 - val_accuracy: 0.9012\n",
      "Epoch 301/500\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.2438 - accuracy: 0.9146 - val_loss: 0.2949 - val_accuracy: 0.9012\n",
      "Epoch 302/500\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.2436 - accuracy: 0.9161 - val_loss: 0.2956 - val_accuracy: 0.8990\n",
      "Epoch 303/500\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.2436 - accuracy: 0.9150 - val_loss: 0.2945 - val_accuracy: 0.8997\n",
      "Epoch 304/500\n",
      "10685/10685 [==============================] - 1s 60us/step - loss: 0.2433 - accuracy: 0.9140 - val_loss: 0.2953 - val_accuracy: 0.8997\n",
      "Epoch 305/500\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.2436 - accuracy: 0.9157 - val_loss: 0.2945 - val_accuracy: 0.8997\n",
      "Epoch 306/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2436 - accuracy: 0.9159 - val_loss: 0.2943 - val_accuracy: 0.8997\n",
      "Epoch 307/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2434 - accuracy: 0.9154 - val_loss: 0.2951 - val_accuracy: 0.8997\n",
      "Epoch 308/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2434 - accuracy: 0.9160 - val_loss: 0.2945 - val_accuracy: 0.9004\n",
      "Epoch 309/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2432 - accuracy: 0.9159 - val_loss: 0.2962 - val_accuracy: 0.8997\n",
      "Epoch 310/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2433 - accuracy: 0.9160 - val_loss: 0.2958 - val_accuracy: 0.8990\n",
      "Epoch 311/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2431 - accuracy: 0.9152 - val_loss: 0.2969 - val_accuracy: 0.8982\n",
      "Epoch 312/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2430 - accuracy: 0.9151 - val_loss: 0.2951 - val_accuracy: 0.8982\n",
      "Epoch 313/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2430 - accuracy: 0.9154 - val_loss: 0.2970 - val_accuracy: 0.8975\n",
      "Epoch 314/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2430 - accuracy: 0.9157 - val_loss: 0.2979 - val_accuracy: 0.8975\n",
      "Epoch 315/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2430 - accuracy: 0.9154 - val_loss: 0.2961 - val_accuracy: 0.9004\n",
      "Epoch 316/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2430 - accuracy: 0.9154 - val_loss: 0.2964 - val_accuracy: 0.8990\n",
      "Epoch 317/500\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2429 - accuracy: 0.9158 - val_loss: 0.2963 - val_accuracy: 0.8997\n",
      "Epoch 318/500\n",
      "10685/10685 [==============================] - 1s 53us/step - loss: 0.2427 - accuracy: 0.9165 - val_loss: 0.2960 - val_accuracy: 0.8997\n",
      "Epoch 319/500\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.2427 - accuracy: 0.9164 - val_loss: 0.2964 - val_accuracy: 0.8990\n",
      "Epoch 320/500\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2427 - accuracy: 0.9156 - val_loss: 0.2963 - val_accuracy: 0.8990\n",
      "Epoch 321/500\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2425 - accuracy: 0.9161 - val_loss: 0.2971 - val_accuracy: 0.8990\n",
      "Epoch 322/500\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2425 - accuracy: 0.9152 - val_loss: 0.2953 - val_accuracy: 0.9004\n",
      "Epoch 323/500\n",
      "10685/10685 [==============================] - 1s 55us/step - loss: 0.2424 - accuracy: 0.9170 - val_loss: 0.2961 - val_accuracy: 0.8990\n",
      "Epoch 324/500\n",
      "10685/10685 [==============================] - 1s 56us/step - loss: 0.2423 - accuracy: 0.9166 - val_loss: 0.2973 - val_accuracy: 0.8990\n",
      "Epoch 325/500\n",
      "10685/10685 [==============================] - 1s 52us/step - loss: 0.2423 - accuracy: 0.9158 - val_loss: 0.2957 - val_accuracy: 0.9004\n",
      "Epoch 326/500\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.2420 - accuracy: 0.9160 - val_loss: 0.2957 - val_accuracy: 0.8997\n",
      "Epoch 327/500\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2421 - accuracy: 0.9165 - val_loss: 0.2955 - val_accuracy: 0.8997\n",
      "Epoch 328/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10685/10685 [==============================] - 0s 36us/step - loss: 0.2421 - accuracy: 0.9163 - val_loss: 0.2962 - val_accuracy: 0.8990\n",
      "Epoch 329/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2420 - accuracy: 0.9157 - val_loss: 0.2973 - val_accuracy: 0.8997\n",
      "Epoch 330/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2421 - accuracy: 0.9161 - val_loss: 0.2960 - val_accuracy: 0.8990\n",
      "Epoch 331/500\n",
      "10685/10685 [==============================] - 0s 36us/step - loss: 0.2418 - accuracy: 0.9159 - val_loss: 0.2963 - val_accuracy: 0.9004\n",
      "Epoch 332/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2421 - accuracy: 0.9160 - val_loss: 0.2965 - val_accuracy: 0.9004\n",
      "Epoch 333/500\n",
      "10685/10685 [==============================] - 1s 47us/step - loss: 0.2417 - accuracy: 0.9152 - val_loss: 0.2965 - val_accuracy: 0.8997\n",
      "Epoch 334/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2418 - accuracy: 0.9167 - val_loss: 0.2957 - val_accuracy: 0.9012\n",
      "Epoch 335/500\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.2418 - accuracy: 0.9166 - val_loss: 0.2974 - val_accuracy: 0.9004\n",
      "Epoch 336/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2417 - accuracy: 0.9159 - val_loss: 0.2962 - val_accuracy: 0.9004\n",
      "Epoch 337/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2417 - accuracy: 0.9158 - val_loss: 0.2958 - val_accuracy: 0.9012\n",
      "Epoch 338/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2415 - accuracy: 0.9167 - val_loss: 0.2969 - val_accuracy: 0.8990\n",
      "Epoch 339/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2416 - accuracy: 0.9168 - val_loss: 0.2978 - val_accuracy: 0.8990\n",
      "Epoch 340/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2416 - accuracy: 0.9169 - val_loss: 0.2971 - val_accuracy: 0.8997\n",
      "Epoch 341/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2414 - accuracy: 0.9174 - val_loss: 0.2955 - val_accuracy: 0.9004\n",
      "Epoch 342/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2415 - accuracy: 0.9164 - val_loss: 0.2963 - val_accuracy: 0.9019\n",
      "Epoch 343/500\n",
      "10685/10685 [==============================] - 1s 50us/step - loss: 0.2415 - accuracy: 0.9159 - val_loss: 0.2961 - val_accuracy: 0.8997\n",
      "Epoch 344/500\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.2411 - accuracy: 0.9162 - val_loss: 0.2978 - val_accuracy: 0.9004\n",
      "Epoch 345/500\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2412 - accuracy: 0.9161 - val_loss: 0.2983 - val_accuracy: 0.9004\n",
      "Epoch 346/500\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.2411 - accuracy: 0.9161 - val_loss: 0.2979 - val_accuracy: 0.8997\n",
      "Epoch 347/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2410 - accuracy: 0.9164 - val_loss: 0.2979 - val_accuracy: 0.8997\n",
      "Epoch 348/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2410 - accuracy: 0.9167 - val_loss: 0.2988 - val_accuracy: 0.9004\n",
      "Epoch 349/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2409 - accuracy: 0.9170 - val_loss: 0.2974 - val_accuracy: 0.9004\n",
      "Epoch 350/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2410 - accuracy: 0.9165 - val_loss: 0.2962 - val_accuracy: 0.9027\n",
      "Epoch 351/500\n",
      "10685/10685 [==============================] - 0s 36us/step - loss: 0.2409 - accuracy: 0.9161 - val_loss: 0.2971 - val_accuracy: 0.9004\n",
      "Epoch 352/500\n",
      "10685/10685 [==============================] - 0s 33us/step - loss: 0.2409 - accuracy: 0.9169 - val_loss: 0.2965 - val_accuracy: 0.9012\n",
      "Epoch 353/500\n",
      "10685/10685 [==============================] - 0s 36us/step - loss: 0.2407 - accuracy: 0.9163 - val_loss: 0.2963 - val_accuracy: 0.9004\n",
      "Epoch 354/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2408 - accuracy: 0.9162 - val_loss: 0.2979 - val_accuracy: 0.8997\n",
      "Epoch 355/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2410 - accuracy: 0.9161 - val_loss: 0.2974 - val_accuracy: 0.8997\n",
      "Epoch 356/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2408 - accuracy: 0.9160 - val_loss: 0.2980 - val_accuracy: 0.9012\n",
      "Epoch 357/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2408 - accuracy: 0.9161 - val_loss: 0.2976 - val_accuracy: 0.9012\n",
      "Epoch 358/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2407 - accuracy: 0.9167 - val_loss: 0.2994 - val_accuracy: 0.8997\n",
      "Epoch 359/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2406 - accuracy: 0.9165 - val_loss: 0.2982 - val_accuracy: 0.9012\n",
      "Epoch 360/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2408 - accuracy: 0.9160 - val_loss: 0.2963 - val_accuracy: 0.9019\n",
      "Epoch 361/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2405 - accuracy: 0.9161 - val_loss: 0.2970 - val_accuracy: 0.9012\n",
      "Epoch 362/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2408 - accuracy: 0.9161 - val_loss: 0.2979 - val_accuracy: 0.9004\n",
      "Epoch 363/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2403 - accuracy: 0.9156 - val_loss: 0.2980 - val_accuracy: 0.8982\n",
      "Epoch 364/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2404 - accuracy: 0.9164 - val_loss: 0.2980 - val_accuracy: 0.9012\n",
      "Epoch 365/500\n",
      "10685/10685 [==============================] - ETA: 0s - loss: 0.2410 - accuracy: 0.91 - 0s 42us/step - loss: 0.2403 - accuracy: 0.9164 - val_loss: 0.2996 - val_accuracy: 0.8990\n",
      "Epoch 366/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2403 - accuracy: 0.9175 - val_loss: 0.2984 - val_accuracy: 0.9012\n",
      "Epoch 367/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2402 - accuracy: 0.9173 - val_loss: 0.2971 - val_accuracy: 0.9004\n",
      "Epoch 368/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2402 - accuracy: 0.9175 - val_loss: 0.2981 - val_accuracy: 0.9004\n",
      "Epoch 369/500\n",
      "10685/10685 [==============================] - ETA: 0s - loss: 0.2369 - accuracy: 0.91 - 0s 38us/step - loss: 0.2402 - accuracy: 0.9173 - val_loss: 0.2973 - val_accuracy: 0.8982\n",
      "Epoch 370/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2401 - accuracy: 0.9170 - val_loss: 0.2971 - val_accuracy: 0.8990\n",
      "Epoch 371/500\n",
      "10685/10685 [==============================] - 0s 32us/step - loss: 0.2401 - accuracy: 0.9167 - val_loss: 0.2987 - val_accuracy: 0.9004\n",
      "Epoch 372/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2401 - accuracy: 0.9162 - val_loss: 0.2973 - val_accuracy: 0.9019\n",
      "Epoch 373/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2401 - accuracy: 0.9161 - val_loss: 0.2987 - val_accuracy: 0.8997\n",
      "Epoch 374/500\n",
      "10685/10685 [==============================] - 0s 34us/step - loss: 0.2400 - accuracy: 0.9164 - val_loss: 0.2985 - val_accuracy: 0.9012\n",
      "Epoch 375/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2400 - accuracy: 0.9172 - val_loss: 0.2979 - val_accuracy: 0.9012\n",
      "Epoch 376/500\n",
      "10685/10685 [==============================] - 0s 36us/step - loss: 0.2400 - accuracy: 0.9173 - val_loss: 0.2978 - val_accuracy: 0.9004\n",
      "Epoch 377/500\n",
      "10685/10685 [==============================] - 0s 33us/step - loss: 0.2399 - accuracy: 0.9167 - val_loss: 0.2987 - val_accuracy: 0.8997\n",
      "Epoch 378/500\n",
      "10685/10685 [==============================] - 0s 32us/step - loss: 0.2401 - accuracy: 0.9160 - val_loss: 0.2979 - val_accuracy: 0.9012\n",
      "Epoch 379/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2397 - accuracy: 0.9172 - val_loss: 0.2976 - val_accuracy: 0.9019\n",
      "Epoch 380/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2396 - accuracy: 0.9175 - val_loss: 0.2979 - val_accuracy: 0.9012\n",
      "Epoch 381/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2398 - accuracy: 0.9170 - val_loss: 0.2988 - val_accuracy: 0.9012\n",
      "Epoch 382/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2396 - accuracy: 0.9180 - val_loss: 0.2982 - val_accuracy: 0.9004\n",
      "Epoch 383/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2397 - accuracy: 0.9164 - val_loss: 0.2975 - val_accuracy: 0.9004\n",
      "Epoch 384/500\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2398 - accuracy: 0.9160 - val_loss: 0.2980 - val_accuracy: 0.9019\n",
      "Epoch 385/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2396 - accuracy: 0.9163 - val_loss: 0.2988 - val_accuracy: 0.9004\n",
      "Epoch 386/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2395 - accuracy: 0.9175 - val_loss: 0.2984 - val_accuracy: 0.9012\n",
      "Epoch 387/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2395 - accuracy: 0.9175 - val_loss: 0.2993 - val_accuracy: 0.9012\n",
      "Epoch 388/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2395 - accuracy: 0.9180 - val_loss: 0.2997 - val_accuracy: 0.8997\n",
      "Epoch 389/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2395 - accuracy: 0.9168 - val_loss: 0.2992 - val_accuracy: 0.9004\n",
      "Epoch 390/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2395 - accuracy: 0.9170 - val_loss: 0.2988 - val_accuracy: 0.9004\n",
      "Epoch 391/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2392 - accuracy: 0.9170 - val_loss: 0.2982 - val_accuracy: 0.9019\n",
      "Epoch 392/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2393 - accuracy: 0.9165 - val_loss: 0.3001 - val_accuracy: 0.9019\n",
      "Epoch 393/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2393 - accuracy: 0.9172 - val_loss: 0.2988 - val_accuracy: 0.9004\n",
      "Epoch 394/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2392 - accuracy: 0.9175 - val_loss: 0.3010 - val_accuracy: 0.8990\n",
      "Epoch 395/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2393 - accuracy: 0.9169 - val_loss: 0.2986 - val_accuracy: 0.9019\n",
      "Epoch 396/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2392 - accuracy: 0.9172 - val_loss: 0.3009 - val_accuracy: 0.8990\n",
      "Epoch 397/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2393 - accuracy: 0.9160 - val_loss: 0.3007 - val_accuracy: 0.9004\n",
      "Epoch 398/500\n",
      "10685/10685 [==============================] - 0s 32us/step - loss: 0.2386 - accuracy: 0.9168 - val_loss: 0.2983 - val_accuracy: 0.9004\n",
      "Epoch 399/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2390 - accuracy: 0.9175 - val_loss: 0.2999 - val_accuracy: 0.9004\n",
      "Epoch 400/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2393 - accuracy: 0.9164 - val_loss: 0.2991 - val_accuracy: 0.9012\n",
      "Epoch 401/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2388 - accuracy: 0.9177 - val_loss: 0.2998 - val_accuracy: 0.9027\n",
      "Epoch 402/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2389 - accuracy: 0.9178 - val_loss: 0.3000 - val_accuracy: 0.9019\n",
      "Epoch 403/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2391 - accuracy: 0.9172 - val_loss: 0.2995 - val_accuracy: 0.9012\n",
      "Epoch 404/500\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2387 - accuracy: 0.9177 - val_loss: 0.3014 - val_accuracy: 0.9027\n",
      "Epoch 405/500\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2391 - accuracy: 0.9171 - val_loss: 0.3001 - val_accuracy: 0.9012\n",
      "Epoch 406/500\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2387 - accuracy: 0.9160 - val_loss: 0.3016 - val_accuracy: 0.9019\n",
      "Epoch 407/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2388 - accuracy: 0.9171 - val_loss: 0.3003 - val_accuracy: 0.9004\n",
      "Epoch 408/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2388 - accuracy: 0.9165 - val_loss: 0.3005 - val_accuracy: 0.9004\n",
      "Epoch 409/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2388 - accuracy: 0.9173 - val_loss: 0.3008 - val_accuracy: 0.9004\n",
      "Epoch 410/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2387 - accuracy: 0.9175 - val_loss: 0.3010 - val_accuracy: 0.8997\n",
      "Epoch 411/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2388 - accuracy: 0.9175 - val_loss: 0.3020 - val_accuracy: 0.8967\n",
      "Epoch 412/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2388 - accuracy: 0.9161 - val_loss: 0.2997 - val_accuracy: 0.9019\n",
      "Epoch 413/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2386 - accuracy: 0.9174 - val_loss: 0.2992 - val_accuracy: 0.9019\n",
      "Epoch 414/500\n",
      "10685/10685 [==============================] - 1s 57us/step - loss: 0.2384 - accuracy: 0.9168 - val_loss: 0.3001 - val_accuracy: 0.9004\n",
      "Epoch 415/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2384 - accuracy: 0.9165 - val_loss: 0.3002 - val_accuracy: 0.8990\n",
      "Epoch 416/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2385 - accuracy: 0.9169 - val_loss: 0.3001 - val_accuracy: 0.9012\n",
      "Epoch 417/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2385 - accuracy: 0.9177 - val_loss: 0.2995 - val_accuracy: 0.9012\n",
      "Epoch 418/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2385 - accuracy: 0.9166 - val_loss: 0.2996 - val_accuracy: 0.9012\n",
      "Epoch 419/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2384 - accuracy: 0.9166 - val_loss: 0.3006 - val_accuracy: 0.9004\n",
      "Epoch 420/500\n",
      "10685/10685 [==============================] - 1s 72us/step - loss: 0.2386 - accuracy: 0.9177 - val_loss: 0.2997 - val_accuracy: 0.8997\n",
      "Epoch 421/500\n",
      "10685/10685 [==============================] - 1s 62us/step - loss: 0.2385 - accuracy: 0.9181 - val_loss: 0.3002 - val_accuracy: 0.9019\n",
      "Epoch 422/500\n",
      "10685/10685 [==============================] - 1s 58us/step - loss: 0.2385 - accuracy: 0.9173 - val_loss: 0.3010 - val_accuracy: 0.9004\n",
      "Epoch 423/500\n",
      "10685/10685 [==============================] - 1s 73us/step - loss: 0.2383 - accuracy: 0.9172 - val_loss: 0.2998 - val_accuracy: 0.9027\n",
      "Epoch 424/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2384 - accuracy: 0.9166 - val_loss: 0.3024 - val_accuracy: 0.8975\n",
      "Epoch 425/500\n",
      "10685/10685 [==============================] - 1s 61us/step - loss: 0.2384 - accuracy: 0.9169 - val_loss: 0.3006 - val_accuracy: 0.9019\n",
      "Epoch 426/500\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2383 - accuracy: 0.9170 - val_loss: 0.3004 - val_accuracy: 0.9019\n",
      "Epoch 427/500\n",
      "10685/10685 [==============================] - 1s 58us/step - loss: 0.2383 - accuracy: 0.9168 - val_loss: 0.2999 - val_accuracy: 0.9012\n",
      "Epoch 428/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2384 - accuracy: 0.9174 - val_loss: 0.3018 - val_accuracy: 0.9012\n",
      "Epoch 429/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2380 - accuracy: 0.9174 - val_loss: 0.2995 - val_accuracy: 0.9012\n",
      "Epoch 430/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2381 - accuracy: 0.9175 - val_loss: 0.3000 - val_accuracy: 0.9019\n",
      "Epoch 431/500\n",
      "10685/10685 [==============================] - 0s 32us/step - loss: 0.2383 - accuracy: 0.9175 - val_loss: 0.3003 - val_accuracy: 0.8997\n",
      "Epoch 432/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2381 - accuracy: 0.9172 - val_loss: 0.3009 - val_accuracy: 0.8990\n",
      "Epoch 433/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2377 - accuracy: 0.9180 - val_loss: 0.3016 - val_accuracy: 0.8967\n",
      "Epoch 434/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2380 - accuracy: 0.9161 - val_loss: 0.3027 - val_accuracy: 0.8997\n",
      "Epoch 435/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2381 - accuracy: 0.9177 - val_loss: 0.3007 - val_accuracy: 0.9012\n",
      "Epoch 436/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2381 - accuracy: 0.9177 - val_loss: 0.3007 - val_accuracy: 0.9004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 437/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2377 - accuracy: 0.9172 - val_loss: 0.3007 - val_accuracy: 0.9004\n",
      "Epoch 438/500\n",
      "10685/10685 [==============================] - 0s 34us/step - loss: 0.2380 - accuracy: 0.9171 - val_loss: 0.3012 - val_accuracy: 0.9004\n",
      "Epoch 439/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2380 - accuracy: 0.9172 - val_loss: 0.3008 - val_accuracy: 0.8997\n",
      "Epoch 440/500\n",
      "10685/10685 [==============================] - 0s 44us/step - loss: 0.2379 - accuracy: 0.9173 - val_loss: 0.3026 - val_accuracy: 0.9019\n",
      "Epoch 441/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2380 - accuracy: 0.9181 - val_loss: 0.3014 - val_accuracy: 0.8990\n",
      "Epoch 442/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2376 - accuracy: 0.9176 - val_loss: 0.3015 - val_accuracy: 0.8997\n",
      "Epoch 443/500\n",
      "10685/10685 [==============================] - 0s 36us/step - loss: 0.2380 - accuracy: 0.9177 - val_loss: 0.3003 - val_accuracy: 0.9019\n",
      "Epoch 444/500\n",
      "10685/10685 [==============================] - 0s 39us/step - loss: 0.2376 - accuracy: 0.9172 - val_loss: 0.3017 - val_accuracy: 0.9012\n",
      "Epoch 445/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2377 - accuracy: 0.9178 - val_loss: 0.3007 - val_accuracy: 0.9004\n",
      "Epoch 446/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2377 - accuracy: 0.9172 - val_loss: 0.3005 - val_accuracy: 0.9004\n",
      "Epoch 447/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2377 - accuracy: 0.9173 - val_loss: 0.3018 - val_accuracy: 0.9019\n",
      "Epoch 448/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2378 - accuracy: 0.9181 - val_loss: 0.3019 - val_accuracy: 0.8997\n",
      "Epoch 449/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2378 - accuracy: 0.9167 - val_loss: 0.3024 - val_accuracy: 0.9012\n",
      "Epoch 450/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2377 - accuracy: 0.9176 - val_loss: 0.3011 - val_accuracy: 0.9004\n",
      "Epoch 451/500\n",
      "10685/10685 [==============================] - 0s 36us/step - loss: 0.2376 - accuracy: 0.9174 - val_loss: 0.3015 - val_accuracy: 0.8997\n",
      "Epoch 452/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2376 - accuracy: 0.9184 - val_loss: 0.3022 - val_accuracy: 0.9004\n",
      "Epoch 453/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2375 - accuracy: 0.9177 - val_loss: 0.3032 - val_accuracy: 0.8990\n",
      "Epoch 454/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2375 - accuracy: 0.9175 - val_loss: 0.3014 - val_accuracy: 0.9027\n",
      "Epoch 455/500\n",
      "10685/10685 [==============================] - 1s 91us/step - loss: 0.2375 - accuracy: 0.9183 - val_loss: 0.3016 - val_accuracy: 0.9004\n",
      "Epoch 456/500\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.2374 - accuracy: 0.9173 - val_loss: 0.3015 - val_accuracy: 0.9012\n",
      "Epoch 457/500\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.2375 - accuracy: 0.9176 - val_loss: 0.3030 - val_accuracy: 0.9004\n",
      "Epoch 458/500\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2374 - accuracy: 0.9172 - val_loss: 0.3033 - val_accuracy: 0.9012\n",
      "Epoch 459/500\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.2372 - accuracy: 0.9174 - val_loss: 0.3023 - val_accuracy: 0.8997\n",
      "Epoch 460/500\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2374 - accuracy: 0.9175 - val_loss: 0.3009 - val_accuracy: 0.9027\n",
      "Epoch 461/500\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.2374 - accuracy: 0.9172 - val_loss: 0.3017 - val_accuracy: 0.8997\n",
      "Epoch 462/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2374 - accuracy: 0.9175 - val_loss: 0.3017 - val_accuracy: 0.9012\n",
      "Epoch 463/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2372 - accuracy: 0.9175 - val_loss: 0.3030 - val_accuracy: 0.8997\n",
      "Epoch 464/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2372 - accuracy: 0.9186 - val_loss: 0.3042 - val_accuracy: 0.8975\n",
      "Epoch 465/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2373 - accuracy: 0.9177 - val_loss: 0.3028 - val_accuracy: 0.9004\n",
      "Epoch 466/500\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.2373 - accuracy: 0.9169 - val_loss: 0.3019 - val_accuracy: 0.9012\n",
      "Epoch 467/500\n",
      "10685/10685 [==============================] - 0s 46us/step - loss: 0.2371 - accuracy: 0.9182 - val_loss: 0.3035 - val_accuracy: 0.9012\n",
      "Epoch 468/500\n",
      "10685/10685 [==============================] - 1s 49us/step - loss: 0.2373 - accuracy: 0.9175 - val_loss: 0.3026 - val_accuracy: 0.8997\n",
      "Epoch 469/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2373 - accuracy: 0.9172 - val_loss: 0.3021 - val_accuracy: 0.9012\n",
      "Epoch 470/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2371 - accuracy: 0.9182 - val_loss: 0.3037 - val_accuracy: 0.8997\n",
      "Epoch 471/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2372 - accuracy: 0.9170 - val_loss: 0.3021 - val_accuracy: 0.9012\n",
      "Epoch 472/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2371 - accuracy: 0.9174 - val_loss: 0.3029 - val_accuracy: 0.8997\n",
      "Epoch 473/500\n",
      "10685/10685 [==============================] - 0s 35us/step - loss: 0.2373 - accuracy: 0.9166 - val_loss: 0.3038 - val_accuracy: 0.8997\n",
      "Epoch 474/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2371 - accuracy: 0.9175 - val_loss: 0.3027 - val_accuracy: 0.9012\n",
      "Epoch 475/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2371 - accuracy: 0.9170 - val_loss: 0.3031 - val_accuracy: 0.8990\n",
      "Epoch 476/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2372 - accuracy: 0.9175 - val_loss: 0.3031 - val_accuracy: 0.9004\n",
      "Epoch 477/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2371 - accuracy: 0.9179 - val_loss: 0.3029 - val_accuracy: 0.9012\n",
      "Epoch 478/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2371 - accuracy: 0.9189 - val_loss: 0.3015 - val_accuracy: 0.8990\n",
      "Epoch 479/500\n",
      "10685/10685 [==============================] - 0s 36us/step - loss: 0.2368 - accuracy: 0.9189 - val_loss: 0.3019 - val_accuracy: 0.8982\n",
      "Epoch 480/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2371 - accuracy: 0.9172 - val_loss: 0.3021 - val_accuracy: 0.9012\n",
      "Epoch 481/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2367 - accuracy: 0.9177 - val_loss: 0.3032 - val_accuracy: 0.8997\n",
      "Epoch 482/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2369 - accuracy: 0.9182 - val_loss: 0.3055 - val_accuracy: 0.8975\n",
      "Epoch 483/500\n",
      "10685/10685 [==============================] - 0s 45us/step - loss: 0.2368 - accuracy: 0.9168 - val_loss: 0.3029 - val_accuracy: 0.8997\n",
      "Epoch 484/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2369 - accuracy: 0.9173 - val_loss: 0.3023 - val_accuracy: 0.9004\n",
      "Epoch 485/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2369 - accuracy: 0.9177 - val_loss: 0.3031 - val_accuracy: 0.9019\n",
      "Epoch 486/500\n",
      "10685/10685 [==============================] - 0s 36us/step - loss: 0.2370 - accuracy: 0.9180 - val_loss: 0.3021 - val_accuracy: 0.9019\n",
      "Epoch 487/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2365 - accuracy: 0.9175 - val_loss: 0.3035 - val_accuracy: 0.8990\n",
      "Epoch 488/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2367 - accuracy: 0.9184 - val_loss: 0.3029 - val_accuracy: 0.9004\n",
      "Epoch 489/500\n",
      "10685/10685 [==============================] - 0s 42us/step - loss: 0.2368 - accuracy: 0.9181 - val_loss: 0.3032 - val_accuracy: 0.9004\n",
      "Epoch 490/500\n",
      "10685/10685 [==============================] - 0s 43us/step - loss: 0.2367 - accuracy: 0.9190 - val_loss: 0.3046 - val_accuracy: 0.8982\n",
      "Epoch 491/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2367 - accuracy: 0.9175 - val_loss: 0.3031 - val_accuracy: 0.9012\n",
      "Epoch 492/500\n",
      "10685/10685 [==============================] - 0s 41us/step - loss: 0.2368 - accuracy: 0.9183 - val_loss: 0.3035 - val_accuracy: 0.9004\n",
      "Epoch 493/500\n",
      "10685/10685 [==============================] - 0s 40us/step - loss: 0.2366 - accuracy: 0.9179 - val_loss: 0.3035 - val_accuracy: 0.9004\n",
      "Epoch 494/500\n",
      "10685/10685 [==============================] - 0s 36us/step - loss: 0.2364 - accuracy: 0.9173 - val_loss: 0.3037 - val_accuracy: 0.9004\n",
      "Epoch 495/500\n",
      "10685/10685 [==============================] - 0s 36us/step - loss: 0.2367 - accuracy: 0.9175 - val_loss: 0.3053 - val_accuracy: 0.8997\n",
      "Epoch 496/500\n",
      "10685/10685 [==============================] - 0s 34us/step - loss: 0.2368 - accuracy: 0.9171 - val_loss: 0.3033 - val_accuracy: 0.9012\n",
      "Epoch 497/500\n",
      "10685/10685 [==============================] - 0s 36us/step - loss: 0.2365 - accuracy: 0.9183 - val_loss: 0.3038 - val_accuracy: 0.9004\n",
      "Epoch 498/500\n",
      "10685/10685 [==============================] - 0s 37us/step - loss: 0.2366 - accuracy: 0.9177 - val_loss: 0.3045 - val_accuracy: 0.8975\n",
      "Epoch 499/500\n",
      "10685/10685 [==============================] - 0s 38us/step - loss: 0.2366 - accuracy: 0.9176 - val_loss: 0.3039 - val_accuracy: 0.9004\n",
      "Epoch 500/500\n",
      "10685/10685 [==============================] - 1s 48us/step - loss: 0.2366 - accuracy: 0.9184 - val_loss: 0.3040 - val_accuracy: 0.9004\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "history=model.fit(X_train, y_train_one_hot,\n",
    "                  validation_data=(X_val, y_val_one_hot), \n",
    "                  epochs=500,\n",
    "                  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'acc')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.ylabel(\"loss\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.ylabel(\"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 0.9180159101544221\n",
      "val acc: 0.9004491017964071\n",
      "test acc: 0.8943820224719101\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(f\"train acc: {accuracy_score(y_train,model.predict_classes(X_train))}\")\n",
    "print(f\"val acc: {accuracy_score(y_val,model.predict_classes(X_val))}\")\n",
    "print(f\"test acc: {accuracy_score(y_test,model.predict_classes(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
